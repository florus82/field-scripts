{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18fcb79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked, t_bound 0.5 and t_ext 0.1\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "import shutil\n",
    "from skimage import measure\n",
    "workhorse = True\n",
    "\n",
    "if workhorse:\n",
    "    origin = 'Aldhani/eoagritwin/'\n",
    "else:\n",
    "    origin = ''\n",
    "\n",
    "# transform unique-pairs array to dict\n",
    "def unique_dict(unique_pairs_array):\n",
    "    valid_dict = {}\n",
    "\n",
    "    for key, value in unique_pairs_array:\n",
    "        if key in valid_dict:\n",
    "            valid_dict[key].append(value)\n",
    "        else:\n",
    "            valid_dict[key] = [value]\n",
    "\n",
    "    return valid_dict\n",
    "\n",
    "def make2000000(x):\n",
    "    s = str(x)\n",
    "    if len(s) == 7:\n",
    "        return int('2' + s[1:] )\n",
    "    else:\n",
    "        return int('2' + s[2:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tile files for prediction\n",
    "path = f'/data/{origin}fields/Auxiliary/grid_search/Brandenburg/256_20_chips_masked_with_and_preds_are_GSA-DE_BRB-2019_cropMask_lines_touch_true_lines_touch_true_linecrop_prediction_extent/intermediates/'\n",
    "files = getFilelist(path, '.tif')\n",
    "files_sub = [file for file in files if '0.1_0.5' in file if '_pred_' in file]\n",
    "\n",
    "# make a physical copy of these files\n",
    "outpath = path.split('256_20')[0] + 'quick_n_dirty/'\n",
    "if len(getFilelist(outpath, '.tif')) != 0:\n",
    "    for file in getFilelist(outpath, '.tif'):\n",
    "        os.remove(file)\n",
    "for file in files_sub:\n",
    "    shutil.copy2(file, outpath + file.split('intermediates/')[-1])\n",
    "\n",
    "files_sub = getFilelist(outpath, '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46707def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a777fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over files to get row and col cuts\n",
    "rows, cols = [], []\n",
    "for file in files_sub:\n",
    "    rows.append(int(file.split('_instance_pred_')[-1].split('_')[0]))\n",
    "    cols.append(int(file.split('_instance_pred_')[-1].split('_')[-1].split('.')[0]))\n",
    "rows.sort()\n",
    "cols.sort()\n",
    "rows = list(set(rows))\n",
    "cols = list(set(cols))\n",
    "rows.sort()\n",
    "cols.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3621ccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/potzschf/mambaforge/envs/workhorse/lib/python3.12/site-packages/osgeo/gdal.py:311: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##### iterate over possible row/col connections and search for fields in neighbouring tiles\n",
    "# start at top-left-corner\n",
    "for row in rows:\n",
    "    for col in cols:\n",
    "\n",
    "        # row = rows[0]\n",
    "        # col = cols[5]\n",
    "        tile1 = [sub for sub in files_sub if f'_{row}_{col}.tif' in sub]\n",
    "        if len(tile1) == 0:\n",
    "            continue\n",
    "        else: \n",
    "            ### check for neighbouring tiles and store result in list\n",
    "            #print(f'_{row}_{col}.tif')\n",
    "            # upper  (row -1)\n",
    "            if rows.index(row)!=0:\n",
    "                upper = [sub for sub in files_sub if f'_{rows[rows.index(row)-1]}_{col}.tif' in sub]\n",
    "            else:\n",
    "                upper = []\n",
    "\n",
    "            # upper right (row -1 and col +1)\n",
    "            if rows.index(row)!=0 and cols.index(col) < len(cols) - 1:\n",
    "                upper_right = [sub for sub in files_sub if f'_{rows[rows.index(row)-1]}_{cols[cols.index(col)+1]}.tif' in sub]\n",
    "            else:\n",
    "                upper_right = []\n",
    "\n",
    "            # right (col +1)\n",
    "            if cols.index(col) < len(cols) - 1:\n",
    "                right = [sub for sub in files_sub if f'_{row}_{cols[cols.index(col)+1]}.tif' in sub]\n",
    "            else:\n",
    "                right = []\n",
    "\n",
    "            # lower right (row +1 and col +1)\n",
    "            if rows.index(row) < len(rows) - 1 and cols.index(col) < len(cols) - 1:\n",
    "                lower_right = [sub for sub in files_sub if f'_{rows[rows.index(row)+1]}_{cols[cols.index(col)+1]}.tif' in sub]\n",
    "            else:\n",
    "                lower_right = []\n",
    "\n",
    "            # bottom (row +1)\n",
    "            if rows.index(row) < len(rows) - 1:\n",
    "                bottom = [sub for sub in files_sub if f'_{rows[rows.index(row)+1]}_{col}.tif' in sub]\n",
    "            else:\n",
    "                bottom = []\n",
    "\n",
    "            if any(len(lst) > 0 for lst in [upper, upper_right, right, lower_right, bottom]):\n",
    "                # load starting tile\n",
    "                ds = gdal.Open(tile1[0])\n",
    "                dat = ds.GetRasterBand(1).ReadAsArray()\n",
    "                \n",
    "                ### check the other tiles\n",
    "                # upper\n",
    "                if len(upper) == 1:\n",
    "                    ds = gdal.Open(upper[0])\n",
    "                    neighbour = ds.GetRasterBand(1).ReadAsArray()\n",
    "                    \n",
    "                    unique_pairs = np.unique(np.stack((dat[0,:], neighbour[-1,:]), axis=1), axis=0)\n",
    "                    valid_pairs = unique_pairs[(unique_pairs != 0).all(axis=1)]\n",
    "                    valid_dict = unique_dict(valid_pairs)\n",
    "                    for v, p_list in valid_dict.items():\n",
    "                        dat[dat == v] = 2000000 + v\n",
    "                        for p in p_list:\n",
    "                            neighbour[neighbour == p] = 2000000 + v\n",
    "                    # export manipulated tile (will overwrite)\n",
    "                    makeTif_np_to_matching_tif(neighbour, upper[0], upper[0], noData=0)\n",
    "\n",
    "                # upper right\n",
    "                if len(upper_right) == 1:\n",
    "                    ds = gdal.Open(upper_right[0])\n",
    "                    neighbour = ds.GetRasterBand(1).ReadAsArray()\n",
    "                    \n",
    "                    unique_pairs = np.unique(np.stack((dat[0,-1], neighbour[-1,0])), axis=0)\n",
    "                    valid_pairs = unique_pairs[(unique_pairs != 0).all()]\n",
    "                    if len(valid_pairs) > 1:\n",
    "                        for v, p in valid_pairs:\n",
    "                            dat[dat == v] = 2000000 + v\n",
    "                            neighbour[neighbour == p] = 2000000 + v\n",
    "                    # export manipulated tile (will overwrite)\n",
    "                    makeTif_np_to_matching_tif(neighbour, upper_right[0], upper_right[0], noData=0)\n",
    "\n",
    "                # right\n",
    "                if len(right) == 1:\n",
    "                    ds = gdal.Open(right[0])\n",
    "                    neighbour = ds.GetRasterBand(1).ReadAsArray()\n",
    "                    \n",
    "                    unique_pairs = np.unique(np.stack((dat[:,-1], neighbour[:,0]), axis=1), axis=0)\n",
    "                    valid_pairs = unique_pairs[(unique_pairs != 0).all(axis=1)]\n",
    "                    valid_dict = unique_dict(valid_pairs)\n",
    "                    for v, p_list in valid_dict.items():\n",
    "                        dat[dat == v] = 2000000 + v\n",
    "                        for p in p_list:\n",
    "                            neighbour[neighbour == p] = 2000000 + v\n",
    "                    # export manipulated tile (will overwrite)\n",
    "                    makeTif_np_to_matching_tif(neighbour, right[0], right[0], noData=0)\n",
    "\n",
    "                # lower right\n",
    "                if len(lower_right) == 1:\n",
    "                    ds = gdal.Open(lower_right[0])\n",
    "                    neighbour = ds.GetRasterBand(1).ReadAsArray()\n",
    "                    \n",
    "                    unique_pairs = np.unique(np.stack((dat[-1,-1], neighbour[0,0])), axis=0)\n",
    "                    valid_pairs = unique_pairs[(unique_pairs != 0).all()]\n",
    "                    if len(valid_pairs) > 1:\n",
    "                        for v, p in valid_pairs:\n",
    "                            dat[dat == v] = 2000000 + v\n",
    "                            neighbour[neighbour == p] = 2000000 + v\n",
    "                    # export manipulated tile (will overwrite)\n",
    "                    makeTif_np_to_matching_tif(neighbour, lower_right[0], lower_right[0], noData=0)\n",
    "\n",
    "                # bottom\n",
    "                if len(bottom) == 1:\n",
    "                    ds = gdal.Open(bottom[0])\n",
    "                    neighbour = ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "                    unique_pairs = np.unique(np.stack((dat[-1,:], neighbour[0,:]), axis=1), axis=0)\n",
    "                    valid_pairs = unique_pairs[(unique_pairs != 0).all(axis=1)]\n",
    "                    valid_dict = unique_dict(valid_pairs)\n",
    "                    for v, p_list in valid_dict.items():\n",
    "                        dat[dat == v] = 2000000 + v\n",
    "                        for p in p_list:\n",
    "                            neighbour[neighbour == p] = 2000000 + v\n",
    "                    # export manipulated tile (will overwrite)\n",
    "                    makeTif_np_to_matching_tif(neighbour, bottom[0], bottom[0], noData=0)\n",
    "\n",
    "                makeTif_np_to_matching_tif(dat, tile1[0], tile1[0], noData=0)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    " \n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14975de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over every tile again and clean up mess (e.g. 20000059, 40000059, 60000059)\n",
    "vec_func = np.vectorize(make2000000,otypes=[int])\n",
    "\n",
    "for file in files_sub:\n",
    "    ds = gdal.Open(file)\n",
    "    arr = ds.GetRasterBand(1).ReadAsArray()\n",
    "    mask = arr > 3000000\n",
    "    arr[mask] = vec_func(arr[mask])\n",
    "    makeTif_np_to_matching_tif(arr, file, file, noData=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a vrt and redo rasterIDs\n",
    "gdal.BuildVRT(f'{outpath}quick_n_dirty.vrt', files_sub)\n",
    "vrt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e259f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Aldhani/users/potzschf/conda/envs/workhorse/lib/python3.12/site-packages/osgeo/gdal.py:311: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds = gdal.Open(f'{outpath}quick_n_dirty.vrt')\n",
    "block = ds.GetRasterBand(1).ReadAsArray()\n",
    "relabelled = measure.label(block, background=0, connectivity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dab7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### polygonize\n",
    "# create an in-memory raster-band with geoinfo of the relabelled array\n",
    "rows, cols = relabelled.shape\n",
    "driver = gdal.GetDriverByName('MEM')  # In-memory raster\n",
    "raster_ds = driver.Create('', cols, rows, 1, gdal.GDT_Int32)\n",
    "raster_ds.GetRasterBand(1).WriteArray(relabelled)\n",
    "raster_ds.SetGeoTransform(ds.GetGeoTransform())\n",
    "raster_ds.SetProjection(ds.GetProjection())\n",
    "src_band = raster_ds.GetRasterBand(1)\n",
    "\n",
    "# create a mask for the background (otherwise it would get a polygon as well)\n",
    "mask_array = (relabelled != 0).astype(np.uint8)\n",
    "mask_ds = driver.Create('', cols, rows, 1, gdal.GDT_Int32)\n",
    "mask_ds.GetRasterBand(1).WriteArray(mask_array)\n",
    "mask_band = mask_ds.GetRasterBand(1)\n",
    "\n",
    "# create output for shp\n",
    "driver = ogr.GetDriverByName('ESRI Shapefile')  # or 'GeoJSON', 'GPKG', etc.\n",
    "out_ds = driver.CreateDataSource(f'{outpath}Fields_polygons.shp')  # Output vector file\n",
    "out_layer = out_ds.CreateLayer('polygons', getSpatRefRas(ds), geom_type=ogr.wkbPolygon)\n",
    "field_defn = ogr.FieldDefn('FieldID', ogr.OFTInteger)\n",
    "out_layer.CreateField(field_defn)\n",
    "\n",
    "# polygonize\n",
    "gdal.Polygonize(src_band, mask_band, out_layer, 0, [], callback=None)\n",
    "del out_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e943e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(f'{outpath}Fields_polygons.shp')\n",
    "check = gdf['FieldID']\n",
    "ids, counts = np.unique(check, return_counts=True)\n",
    "print(np.sum(counts > 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2519aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST TO EXPORT THE RASTER !!!!!\n",
    "\n",
    "tif_driver = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "#### polygonize\n",
    "# create an in-memory raster-band with geoinfo of the relabelled array\n",
    "rows, cols = relabelled.shape\n",
    "driver = gdal.GetDriverByName('MEM')  # In-memory raster\n",
    "raster_ds = driver.Create('', cols, rows, 1, gdal.GDT_Int32)\n",
    "raster_ds.GetRasterBand(1).WriteArray(relabelled)\n",
    "raster_ds.SetGeoTransform(ds.GetGeoTransform())\n",
    "raster_ds.SetProjection(ds.GetProjection())\n",
    "src_band = raster_ds.GetRasterBand(1)\n",
    "\n",
    "# create a mask for the background (otherwise it would get a polygon as well)\n",
    "mask_array = (relabelled != 0).astype(np.uint8)\n",
    "mask_ds = driver.Create('', cols, rows, 1, gdal.GDT_Int32)\n",
    "mask_ds.GetRasterBand(1).WriteArray(mask_array)\n",
    "mask_band = mask_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "tif_ds = tif_driver.CreateCopy(f'{outpath}BRA_MASK.tif', raster_ds, strict=0)\n",
    "tif_ds.GetRasterBand(1).SetNoDataValue(0)\n",
    "tif_ds.FlushCache()\n",
    "tif_ds = None\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
