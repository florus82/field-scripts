{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb4d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/media/')\n",
    "# from helperToolz.helpsters import *\n",
    "# from helperToolz.dicts_and_lists import *\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.dicts_and_lists import *\n",
    "from helperToolz.guzinski import *\n",
    "from skimage import measure\n",
    "from skimage.measure import regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c491e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2023\n",
    "model_name = 'AI4_RGB_exclude_False_47'\n",
    "ncores = 56\n",
    "\n",
    "\n",
    "pred_list = [file for file in getFilelist(f'/data/Aldhani/eoagritwin/fields/output/predictions/FORCE/BRANDENBURG/{model_name}/{year}/vrt/', '.vrt')\\\n",
    "              if 'unmasked' not in file]\n",
    "ref_list = [file for file in getFilelist(f'/data/Aldhani/eoagritwin/fields/IACS/4_Crop_mask/{year}/', '.tif') if 'prediction_extent' in file]\n",
    "\n",
    "pred_list_sorted, ref_list_sorted = [], []\n",
    "for pred in pred_list:\n",
    "    for ref in ref_list:\n",
    "        if '_'.join(pred.split('/')[-1].split('_')[:-2]) == ref.split('cropMask_')[-1].split('_prediction_extent')[0]:\n",
    "            pred_list_sorted.append(pred)\n",
    "            ref_list_sorted.append(ref)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f229e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2023\n",
    "\n",
    "pred_list = [file for file in getFilelist(f'/data/Aldhani/eoagritwin/fields/output/predictions/FORCE/BRANDENBURG/{year}/vrt/', '.vrt') if 'unmasked' not in file]\n",
    "ref_list = [file for file in getFilelist(f'/data/Aldhani/eoagritwin/fields/IACS/4_Crop_mask/{year}/', '.tif') if 'prediction_extent' in file]\n",
    "\n",
    "pred_list_sorted, ref_list_sorted = [], []\n",
    "for pred in pred_list:\n",
    "    for ref in ref_list:\n",
    "        if '_'.join(pred.split('/')[-1].split('_')[:-2]) == ref.split('cropMask_')[-1].split('_prediction_extent')[0]:\n",
    "            pred_list_sorted.append(pred)\n",
    "            ref_list_sorted.append(ref)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42847938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GSA-DE_BRB-2023_cropMask_lines_touch_false_crop_touch_false_prediction_extent'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pred_list_sorted[0]\n",
    "reference = ref_list_sorted[0]\n",
    "reference.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d3de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pixel excluded - [0, 1.0, 5.0, 49.0, 105.0, 205.0, 405.0, 856.0, 1995.0, 5671.0, np.int64(259902)]\n",
      "1 pixel excluded - [0, 2.0, 4.0, 9.0, 30.0, 68.0, 136.0, 269.0, 541.0, 1231.0, np.int64(24316)]\n",
      "0 pixel excluded - [0, 73.0, 110.0, 160.0, 237.0, 352.0, 544.0, 909.0999999999995, 1770.5999999999985, 4888.80000000001, np.int64(1386382)]\n",
      "2 pixel excluded - [0, 3.0, 4.0, 7.0, 18.0, 49.0, 107.0, 223.0, 478.0, 1131.0, np.int64(24317)]\n",
      "0 pixel excluded - [0, 1.0, 5.0, 49.0, 105.0, 205.0, 405.0, 856.0, 1995.0, 5671.0, np.int64(259902)]\n",
      "1 pixel excluded - [0, 2.0, 4.0, 15.0, 39.0, 81.0, 157.0, 298.0, 584.0, 1293.0, np.int64(24149)]\n",
      "0 pixel excluded - [0, 73.0, 110.0, 160.0, 237.0, 352.0, 544.0, 909.0999999999995, 1770.5999999999985, 4888.80000000001, np.int64(1386382)]\n",
      "1 pixel excluded - [0, 2.0, 3.0, 8.0, 25.0, 61.0, 126.0, 253.0, 520.0, 1197.0, np.int64(24149)]\n"
     ]
    }
   ],
   "source": [
    "for prediction, reference in zip(pred_list_sorted, ref_list_sorted):\n",
    "\n",
    "    # set the number by which rows and cols will be divided --> determines the number of tiles // also set border limit (dont sample fields too close to tile borders) and sample size\n",
    "    slicer = 10\n",
    "    border_limit = 5\n",
    "    sample_size  = 10000\n",
    "    # set the number of cores for parallel processing and set seed\n",
    "    ncores = 55\n",
    "    np.random.seed(42)\n",
    "    make_tifs_from_intermediate_step = True\n",
    "\n",
    "    ######### prepare job-list\n",
    "\n",
    "    # create lists that will be passed on to the joblist\n",
    "    # tile_list = []\n",
    "    extent_true_list = []\n",
    "    extent_pred_list = []\n",
    "    boundary_pred_list = []\n",
    "    result_dir_list = []\n",
    "    row_col_start = []\n",
    "\n",
    "\n",
    "    # tile predictions in prds --> total extent encompasses 90 Force Tiles (+ a few rows and cols that will be neglected as they are outside of study area)\n",
    "    pred_ds = gdal.Open(prediction)\n",
    "    rows, cols = pred_ds.RasterYSize, pred_ds.RasterXSize\n",
    "\n",
    "    row_start = [i for i in range(0, rows, math.floor(rows/slicer))]\n",
    "    row_end = [i for i in range (math.floor(rows/slicer), rows, math.floor(rows/slicer))]\n",
    "    row_start = row_start[:len(row_end)] \n",
    "\n",
    "    col_start = [i for i in range(0, cols, math.floor(cols/slicer))]\n",
    "    col_end = [i for i in range (math.floor(cols/slicer), cols, math.floor(cols/slicer))]\n",
    "    col_start = col_start[:len(col_end)] \n",
    "\n",
    "        # load IACS reference mask and label it \n",
    "    ref_ds = gdal.Open(reference)\n",
    "    extent_true = ref_ds.GetRasterBand(1).ReadAsArray()\n",
    "    binary_true = extent_true > 0\n",
    "    instances_true = measure.label(binary_true, background=0, connectivity=1)\n",
    "\n",
    "    # sample fields\n",
    "    # build a mask to exclude fields that are in border_limit to tile borders\n",
    "    power_mask = np.zeros(instances_true.shape)\n",
    "    for i in range(len(row_end)):\n",
    "        for j in range(len(col_end)):\n",
    "                power_mask[row_start[i]:row_start[i] + border_limit, :] = 1\n",
    "                power_mask[:, col_start[j]:col_start[j] + border_limit] = 1\n",
    "                power_mask[row_end[-1] - border_limit:power_mask.shape[0], :] = 1\n",
    "                power_mask[:, col_end[-1] - border_limit:power_mask.shape[1]] = 1\n",
    "\n",
    "    # get IDs from labelled reference\n",
    "    IDs_to_skip = np.unique(instances_true[power_mask==1])\n",
    "\n",
    "    # get distribution of field sizes after segmentation\n",
    "    unique_IDs, counts = np.unique(instances_true, return_counts=True)\n",
    "\n",
    "    # exlcude fields that are too close to tile borders\n",
    "    mask = ~np.isin(unique_IDs, IDs_to_skip)\n",
    "    unique_IDs = unique_IDs[mask]\n",
    "    counts = counts[mask]\n",
    "\n",
    "    # exlude 0 (background) and super-small fields (~2 pixel) from sample\n",
    "    pixelthresh = 0\n",
    "\n",
    "    while True:\n",
    "        mask = (unique_IDs != 0)  & (counts > pixelthresh)\n",
    "        unique_IDs = unique_IDs[mask]\n",
    "        counts = counts[mask]\n",
    "\n",
    "        # get deciles and draw equally from them\n",
    "        deciles = [perc for perc in range(10,100,10)]\n",
    "        deciles_values = np.percentile(counts, deciles)\n",
    "        decs = [0] + deciles_values.tolist() + [np.max(counts)]\n",
    "\n",
    "        if len(decs) == len(set(decs)):\n",
    "            df = pd.DataFrame({'decile_value': decs,\n",
    "                   'excluded_pixel':pixelthresh})\n",
    "            df.to_csv(\"decs_output.csv\", index=False)\n",
    "            break\n",
    "        else:\n",
    "            pixelthresh += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcd31eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ids = []\n",
    "for ind in range(len(decs) -1):\n",
    "    # get the unique_IDS of those fields, whose count (size) is within bin\n",
    "    bin_ids.append(np.random.choice(unique_IDs[(counts > decs[ind]) & (counts <= decs[ind + 1])], int(sample_size/10), replace=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f7cffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_true = np.where(np.isin(instances_true, np.concatenate(bin_ids)),\n",
    "                        instances_true,\n",
    "                        0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16755027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      8,     18, ..., 398184, 398207, 398266],\n",
       "      shape=(10001,), dtype=int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(instances_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67b7ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "t_exts = [i/100 for i in range(10,95,5)] \n",
    "t_bounds = [i/100 for i in range(10,95,5)]\n",
    "for t_ext in t_exts:\n",
    "    for t_bound in t_bounds:\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bin_ids = []\n",
    "for ind in range(len(decs) -1):\n",
    "    # get the unique_IDS of those fields, whose count (size) is within bin\n",
    "    bin_ids.append(np.random.choice(unique_IDs[(counts > decs[ind]) & (counts <= decs[ind + 1])], int(sample_size/10), replace=False))\n",
    "\n",
    "instances_true = np.where(np.isin(instances_true, np.concatenate(bin_ids)),\n",
    "                        instances_true,\n",
    "                        0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea68abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathi = '/data/Aldhani/eoagritwin/fields/Auxiliary/grid_search/Brandenburg/2023/test1/unmasked_chips_256_20GSA-DE_BRB-2023_cropMask_lines_touch_true_crop_touch_true_linecrop_prediction_extent/intermediates/'\n",
    "\n",
    "\n",
    "instances_pred = stackReader(checkPath(f'{pathi}0.4_0.2_instance_pred_10760_17982.tif'))\n",
    "instances_true = stackReader(checkPath(f'{pathi}0.4_0.2_instance_true_10760_17982.tif'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "827de853",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_col_start = '10760_17982'\n",
    "\n",
    "# --- 1) get predicted instance segmentation and relabel to 1..N (background 0) ---\n",
    "instances_pred_raw = instances_pred\n",
    "\n",
    "# Robust labeling: treat zeros as background; produce labels 0..P\n",
    "binary_pred = instances_pred_raw != 0\n",
    "instances_pred = measure.label(binary_pred, background=0)  # labels start at 1 for objects\n",
    "\n",
    "# Flatten arrays once for a single-pass overlap computation\n",
    "flat_true = instances_true.ravel()\n",
    "flat_pred = instances_pred.ravel()\n",
    "\n",
    "max_true_label = int(flat_true.max()) if flat_true.size else 0\n",
    "max_pred_label = int(flat_pred.max()) if flat_pred.size else 0\n",
    "\n",
    "# Build intersection matrix: rows=true-label, cols=pred-label\n",
    "# intersection[i, j] = number of pixels where true==i and pred==j\n",
    "# allocate (max_true_label+1, max_pred_label+1) to include the zero label row/col\n",
    "intersection = np.zeros((max_true_label + 1, max_pred_label + 1), dtype=np.int32)\n",
    "\n",
    "# Count only where both are non-zero (optional: we will still fill zeros row/col but it's faster to limit)\n",
    "valid_mask = (flat_true > 0) & (flat_pred > 0)\n",
    "if np.any(valid_mask):\n",
    "    np.add.at(intersection, (flat_true[valid_mask], flat_pred[valid_mask]), 1)\n",
    "\n",
    "# Compute per-label areas using bincount (includes zero index)\n",
    "area_true = np.bincount(flat_true, minlength=(max_true_label + 1)).astype(np.int32)\n",
    "area_pred = np.bincount(flat_pred, minlength=(max_pred_label + 1)).astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c03d674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7927120,       0,       0, ...,       0,       0,      21],\n",
       "      shape=(228198,), dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Avoid division by zero: union = A_true + A_pred - intersection\n",
    "# Vectorized IoU table (shape: (max_true_label+1, max_pred_label+1))\n",
    "# We'll compute IoU only for labels >0 later; but it's fine to compute whole table.\n",
    "union = (area_true[:, None] + area_pred[None, :] - intersection).astype(np.int32)\n",
    "# protect against zero union by setting union to 1 where zero (IoU will be 0 because intersection is also 0)\n",
    "zero_union_mask = union == 0\n",
    "union_safe = union.copy()\n",
    "union_safe[zero_union_mask] = 1\n",
    "IoU_table = intersection / union_safe.astype(np.float32)\n",
    "IoU_table[zero_union_mask] = 0.0  # ensure 0 where union was actually zero\n",
    "\n",
    "# --- 3) prepare outputs in the same order the original iterated (np.unique order) ---\n",
    "field_values = np.unique(instances_true)\n",
    "# allocate lists\n",
    "best_IoUs = []\n",
    "centroid_rows = []\n",
    "centroid_cols = []\n",
    "centroid_IDs = []\n",
    "centroid_IoUS = []\n",
    "field_IDs = []\n",
    "field_sizes = []\n",
    "intersect_IDs = []\n",
    "pred_field_overlap = []\n",
    "\n",
    "# use regionprops for centroid & area extraction (map label -> region)\n",
    "props_true = regionprops(instances_true)  # returns list of RegionProperties for labels > 0\n",
    "# create mapping label -> RegionProperties for quick access\n",
    "props_map = {p.label: p for p in props_true}\n",
    "\n",
    "# we'll also need to get predicted label areas quickly (area_pred array already computed)\n",
    "# and to access instances_pred by centroid coordinates\n",
    "\n",
    "for fv in field_values:\n",
    "    if fv == 0:\n",
    "        continue\n",
    "\n",
    "    field_IDs.append(int(fv))\n",
    "    # area of the true field (from bincount)\n",
    "    f_area = int(area_true[int(fv)])\n",
    "    field_sizes.append(f_area)\n",
    "\n",
    "    # centroid from regionprops (fallback if missing)\n",
    "    if fv in props_map:\n",
    "        centroid = props_map[fv].centroid  # (row, col) floats\n",
    "        r = int(round(centroid[0]))\n",
    "        c = int(round(centroid[1]))\n",
    "    else:\n",
    "        # fallback: compute centroid from coordinates (rare)\n",
    "        coords = np.column_stack(np.where(instances_true == fv))\n",
    "        if coords.size == 0:\n",
    "            r, c = 0, 0\n",
    "        else:\n",
    "            mean_coords = np.mean(coords, axis=0)\n",
    "            r, c = int(round(mean_coords[0])), int(round(mean_coords[1]))\n",
    "\n",
    "    centroid_rows.append(int(r))\n",
    "    centroid_cols.append(int(c))\n",
    "\n",
    "    # find best predicted partner by IoU for this true label\n",
    "    # Only consider pred labels >=1 .. max_pred_label\n",
    "    if int(fv) <= max_true_label and max_pred_label >= 1:\n",
    "        row_iou = IoU_table[int(fv), 1:(max_pred_label + 1)]  # exclude pred label 0\n",
    "        if row_iou.size == 0 or np.all(row_iou == 0):\n",
    "            best_j_rel = -1\n",
    "            best_iou_val = 0.0\n",
    "            best_pred_label = 0\n",
    "        else:\n",
    "            best_j_idx = np.argmax(row_iou)  # index in row_iou\n",
    "            best_iou_val = float(row_iou[best_j_idx])\n",
    "            best_pred_label = int(1 + best_j_idx)  # convert back to actual pred label\n",
    "    else:\n",
    "        best_pred_label = 0\n",
    "        best_iou_val = 0.0\n",
    "\n",
    "    best_IoUs.append(best_iou_val)\n",
    "    intersect_IDs.append(int(best_pred_label))\n",
    "\n",
    "    # compute predicted-field overlap fraction: intersection / pred_field_area\n",
    "    if best_pred_label > 0:\n",
    "        inter_area = int(intersection[int(fv), int(best_pred_label)])\n",
    "        pred_area = int(area_pred[int(best_pred_label)]) if int(best_pred_label) <= max_pred_label else 0\n",
    "        overlap_frac = (inter_area / pred_area) if pred_area > 0 else 0.0\n",
    "    else:\n",
    "        overlap_frac = 0.0\n",
    "    pred_field_overlap.append(overlap_frac)\n",
    "\n",
    "    # centroid-based predicted id and IoU\n",
    "    # ensure centroid coordinates are inside bounds\n",
    "    hr, hc = instances_pred.shape\n",
    "    if 0 <= r < hr and 0 <= c < hc:\n",
    "        pred_at_centroid = int(instances_pred[r, c])\n",
    "    else:\n",
    "        pred_at_centroid = 0\n",
    "\n",
    "    centroid_IDs.append(pred_at_centroid)\n",
    "    # centroid IoU: IoU_table[true_label, pred_at_centroid] if pred_at_centroid>0 else 0\n",
    "    if pred_at_centroid > 0 and int(fv) <= max_true_label and pred_at_centroid <= max_pred_label:\n",
    "        centroid_iou_val = float(IoU_table[int(fv), pred_at_centroid])\n",
    "    else:\n",
    "        centroid_iou_val = 0.0\n",
    "    centroid_IoUS.append(centroid_iou_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
