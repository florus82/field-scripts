{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb4d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/media/')\n",
    "# from helperToolz.helpsters import *\n",
    "# from helperToolz.dicts_and_lists import *\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.dicts_and_lists import *\n",
    "from helperToolz.guzinski import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2dfd48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "\n",
    "reference = f'/data/Aldhani/eoagritwin/fields/IACS/4_Crop_mask/{year}/GSA-DE_BRB-2019_cropMask_lines_touch_true_lines_touch_true_linecrop_prediction_extent.tif'\n",
    "\n",
    "    \n",
    "predictions =  f'/data/Aldhani/eoagritwin/fields/output/predictions/FORCE/BRANDENBURG/{year}/vrt/256_20_chips.vrt' # predictions straight from GPU \n",
    "   \n",
    "    \n",
    "result_dir = f'/data/Aldhani/eoagritwin/fields/Auxiliary/grid_search/Brandenburg/{year}/' + predictions.split('/')[-1].split('.')[0] + '_preds_are_' + reference.split('/')[-1].split('.')[0]\n",
    "sub = predictions.split('/')[-1].split('.')[0] + '_preds_are_' + reference.split('/')[-1].split('.')[0]\n",
    "folder_path = f'{result_dir}/intermediates/'\n",
    "vrt_for_folder_path = folder_path + 'vrt/'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "os.makedirs(vrt_for_folder_path, exist_ok=True)\n",
    "os.makedirs(result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dfbd4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Aldhani/users/potzschf/conda/envs/workhorse/lib/python3.12/site-packages/osgeo/gdal.py:311: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# set the number by which rows and cols will be divided --> determines the number of tiles // also set border limit (dont sample fields too close to tile borders) and sample size\n",
    "slicer = 10\n",
    "border_limit = 5\n",
    "sample_size  = 10000\n",
    "# set the number of cores for parallel processing and set seed\n",
    "ncores = 30\n",
    "np.random.seed(42)\n",
    "make_tifs_from_intermediate_step = True\n",
    "######### prepare job-list\n",
    "\n",
    "\n",
    "# create lists that will be passed on to the joblist\n",
    "tile_list = []\n",
    "extent_true_list = []\n",
    "extent_pred_list = []\n",
    "boundary_pred_list = []\n",
    "result_dir_list = []\n",
    "row_col_start = []\n",
    "\n",
    "\n",
    "# tile predictions in prds --> total extent encompasses 90 Force Tiles (+ a few rows and cols that will be neglected as they are outside of study area)\n",
    "pred_ds = gdal.Open(predictions)\n",
    "rows, cols = pred_ds.RasterYSize, pred_ds.RasterXSize\n",
    "\n",
    "row_start = [i for i in range(0, rows, math.floor(rows/slicer))]\n",
    "row_end = [i for i in range (math.floor(rows/slicer), rows, math.floor(rows/slicer))]\n",
    "row_start = row_start[:len(row_end)] \n",
    "\n",
    "col_start = [i for i in range(0, cols, math.floor(cols/slicer))]\n",
    "col_end = [i for i in range (math.floor(cols/slicer), cols, math.floor(cols/slicer))]\n",
    "col_start = col_start[:len(col_end)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2cc307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyramids created\n"
     ]
    }
   ],
   "source": [
    "# load IACS reference mask and label it \n",
    "ref_ds = gdal.Open(reference)\n",
    "extent_true = ref_ds.GetRasterBand(1).ReadAsArray()\n",
    "binary_true = extent_true > 0\n",
    "instances_true = measure.label(binary_true, background=0, connectivity=1)\n",
    "\n",
    "# sample fields\n",
    "# build a mask to exclude fields that are in border_limit to tile borders\n",
    "power_mask = np.zeros(instances_true.shape)\n",
    "for i in range(len(row_end)):\n",
    "    for j in range(len(col_end)):\n",
    "            power_mask[row_start[i]:row_start[i] + border_limit, :] = 1\n",
    "            power_mask[:, col_start[j]:col_start[j] + border_limit] = 1\n",
    "            power_mask[row_end[-1] - border_limit:power_mask.shape[0], :] = 1\n",
    "            power_mask[:, col_end[-1] - border_limit:power_mask.shape[1]] = 1\n",
    "if make_tifs_from_intermediate_step:\n",
    "    makeTif_np_to_matching_tif(power_mask, reference, vrt_for_folder_path + 'powermask.tif', 0)\n",
    "    makePyramidsForTif(vrt_for_folder_path + 'powermask.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43e73ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyramids created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get IDs from labelled reference\n",
    "IDs_to_skip = np.unique(instances_true[power_mask==1])\n",
    "\n",
    "# get distribution of field sizes after segmentation\n",
    "unique_IDs, counts = np.unique(instances_true, return_counts=True)\n",
    "\n",
    "# exlcude fields that are too close to tile borders\n",
    "mask = ~np.isin(unique_IDs, IDs_to_skip)\n",
    "unique_IDs = unique_IDs[mask]\n",
    "counts = counts[mask]\n",
    "\n",
    "if make_tifs_from_intermediate_step:\n",
    "    # Create filtered array with only valid IDs preserved for export\n",
    "    filtered_instances = np.where(np.isin(instances_true, unique_IDs), instances_true, 0)\n",
    "    makeTif_np_to_matching_tif(filtered_instances, reference, vrt_for_folder_path + 'chips_border_cut.tif', 0, gdalType=gdal.GDT_UInt32)\n",
    "    makePyramidsForTif(vrt_for_folder_path + 'chips_border_cut.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4feee203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyramids created\n"
     ]
    }
   ],
   "source": [
    "# exlude 0 (background) and 1 (super-small fields) from sample\n",
    "mask = (unique_IDs != 0) & (counts > 3)\n",
    "unique_IDs = unique_IDs[mask]\n",
    "counts = counts[mask]\n",
    "\n",
    "\n",
    "# get deciles and draw equally from them\n",
    "deciles = [perc for perc in range(10,100,10)]\n",
    "deciles_values = np.percentile(counts, deciles)\n",
    "decs = [0] + deciles_values.tolist() + [np.max(counts)]\n",
    "bin_ids = []\n",
    "for ind in range(len(decs) -1):\n",
    "    # get the unique_IDS of those fields, whose count (size) is within bin\n",
    "    bin_ids.append(np.random.choice(unique_IDs[(counts > decs[ind]) & (counts <= decs[ind + 1])], int(sample_size/10), replace=False))\n",
    "\n",
    "mask = np.isin(instances_true, np.concatenate(bin_ids))\n",
    "# set everything to 0 except samples\n",
    "instances_true[~mask] = 0\n",
    "\n",
    "if make_tifs_from_intermediate_step:\n",
    "    # Create filtered array with only valid IDs preserved for export\n",
    "    filtered_instances = np.where(np.isin(instances_true, unique_IDs), instances_true, 0)\n",
    "    makeTif_np_to_matching_tif(filtered_instances, reference, vrt_for_folder_path + 'valid_IDs.tif', 0)\n",
    "    makePyramidsForTif(vrt_for_folder_path + 'valid_IDs.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3af3b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in vrt in tiles\n",
    "for i in range(len(row_end)):\n",
    "    for j in range(len(col_end)):\n",
    "        \n",
    "        ######### fill the lists with tiled data\n",
    "\n",
    "        \n",
    "        #subset the prediction of fields read-in\n",
    "        extent_pred = pred_ds.GetRasterBand(1).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i]) # goes into InstSegm --> image of crop probability \n",
    "        # mask extend_pred with reference (rasterized IACS)\n",
    "        extent_pred_masked = extent_pred * extent_true[row_start[i]:row_end[i], col_start[j]:col_end[j]]\n",
    "\n",
    "        # check if prediction subset of fields actually contains data\n",
    "        if len(np.unique(extent_pred_masked)) == 1:\n",
    "            continue\n",
    "        # check if tile contains a sample of reference/label data\n",
    "        extent_true_label = instances_true[row_start[i]:row_end[i], col_start[j]:col_end[j]]\n",
    "        if len(np.unique(extent_true_label)) == 1:\n",
    "            continue\n",
    "        \n",
    "        extent_true_list.append(extent_true_label)\n",
    "        # extent_pred_list.append(extent_pred_masked)\n",
    "        extent_pred_list.append(extent_pred)\n",
    "        # make identifier for tile for csv\n",
    "        tile_list.append(f'{str(i)}_{str(j)}')\n",
    "        # load predicted boundary prob subset // goes into InstSegm --> image of boundary probability\n",
    "        boundary_pred_list.append(pred_ds.GetRasterBand(2).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i])) \n",
    "        # output folder\n",
    "        result_dir_list.append(result_dir)\n",
    "        row_col_start.append(str(row_start[i]) + '_' + str(col_start[j]))\n",
    "\n",
    "        # double check\n",
    "        export_intermediate_products(str(row_start[i]) + '_' + str(col_start[j]), extent_pred_masked, pred_ds.GetGeoTransform(), pred_ds.GetProjection(),\\\n",
    "                              '/data/Aldhani/eoagritwin/fields/Auxiliary/', filename='extend_pred_masked_false_' + str(row_start[i]) + '_' + str(col_start[j]) + '.tif', noData=0, typ='float')\n",
    "        \n",
    "        export_intermediate_products(str(row_start[i]) + '_' + str(col_start[j]), extent_pred, pred_ds.GetGeoTransform(), pred_ds.GetProjection(),\\\n",
    "                              '/data/Aldhani/eoagritwin/fields/Auxiliary/', filename='extend_pred_false_' + str(row_start[i]) + '_' + str(col_start[j]) + '.tif', noData=0, typ='float')\n",
    "\n",
    "jobs = [[tile_list[i], row_col_start[i] ,extent_true_list[i], extent_pred_list[i], boundary_pred_list[i], result_dir_list[i],  pred_ds.GetGeoTransform(), pred_ds.GetProjection(), folder_path, border_limit]  for i in range(len(result_dir_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d15381b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_6',\n",
       " '0_17982',\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], shape=(2690, 2997), dtype=int32),\n",
       " array([[6.8692411e-03, 7.2824727e-03, 8.0832476e-03, ..., 5.0501334e-05,\n",
       "         4.2645759e-05, 6.2255873e-05],\n",
       "        [6.4477636e-03, 6.8899416e-03, 7.7048684e-03, ..., 5.2344083e-05,\n",
       "         4.0627383e-05, 6.4533589e-05],\n",
       "        [6.2481272e-03, 6.6974997e-03, 7.5354176e-03, ..., 6.7245397e-05,\n",
       "         6.2565705e-05, 9.9917932e-05],\n",
       "        ...,\n",
       "        [1.5148680e-03, 1.4788546e-03, 1.5733563e-03, ..., 5.6674510e-02,\n",
       "         1.4226841e-04, 3.2422763e-06],\n",
       "        [1.5173178e-03, 1.4819446e-03, 1.5775257e-03, ..., 1.8040824e-01,\n",
       "         4.2959020e-02, 4.8702830e-05],\n",
       "        [1.5183049e-03, 1.4825736e-03, 1.5791571e-03, ..., 5.0276697e-01,\n",
       "         1.3615446e-01, 9.2795091e-03]], shape=(2690, 2997), dtype=float32),\n",
       " array([[8.8232057e-03, 1.3953138e-02, 1.9799154e-02, ..., 9.4563392e-04,\n",
       "         9.5675047e-04, 1.1075748e-03],\n",
       "        [8.1887338e-03, 1.3053811e-02, 1.8945998e-02, ..., 8.5379672e-04,\n",
       "         1.0076228e-03, 1.0598032e-03],\n",
       "        [7.7676033e-03, 1.2416562e-02, 1.8346841e-02, ..., 9.1601687e-04,\n",
       "         9.2105835e-04, 1.0186248e-03],\n",
       "        ...,\n",
       "        [9.0588495e-04, 1.1359466e-03, 2.0995962e-03, ..., 9.3229890e-01,\n",
       "         5.7762361e-01, 2.7739349e-01],\n",
       "        [9.0428477e-04, 1.1384392e-03, 2.1118894e-03, ..., 9.6574825e-01,\n",
       "         9.0169120e-01, 4.6452284e-01],\n",
       "        [9.0104190e-04, 1.1363204e-03, 2.1100170e-03, ..., 9.4399291e-01,\n",
       "         9.6674311e-01, 8.6147892e-01]], shape=(2690, 2997), dtype=float32),\n",
       " '/data/Aldhani/eoagritwin/fields/Auxiliary/grid_search/Brandenburg/2019/256_20_chips_preds_are_GSA-DE_BRB-2019_cropMask_lines_touch_true_lines_touch_true_linecrop_prediction_extent',\n",
       " (4376126.3630416505, 10.0, 0.0, 3404819.6079648044, 0.0, -10.0),\n",
       " 'PROJCS[\"ETRS89-extended / LAEA Europe\",GEOGCS[\"ETRS89\",DATUM[\"European_Terrestrial_Reference_System_1989\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6258\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4258\"]],PROJECTION[\"Lambert_Azimuthal_Equal_Area\"],PARAMETER[\"latitude_of_center\",52],PARAMETER[\"longitude_of_center\",10],PARAMETER[\"false_easting\",4321000],PARAMETER[\"false_northing\",3210000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Northing\",NORTH],AXIS[\"Easting\",EAST],AUTHORITY[\"EPSG\",\"3035\"]]',\n",
       " '/data/Aldhani/eoagritwin/fields/Auxiliary/grid_search/Brandenburg/2019/256_20_chips_preds_are_GSA-DE_BRB-2019_cropMask_lines_touch_true_lines_touch_true_linecrop_prediction_extent/intermediates/',\n",
       " 5]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
