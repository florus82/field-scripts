{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077edb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from skimage import measure\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "\n",
    "\n",
    "#########################  parameter settings\n",
    "# load the predictions and labels\n",
    "predictions =  '/data/fields/output/predictions/FORCE/BRANDENBURG/vrt/256_20_chips.vrt' # predictions straight from GPU \n",
    "reference =  '/data/fields/IACS/4_Crop_mask/GSA-DE_BRB-2019_cropMask_lines_touch_false_lines_touch_false_linecrop.tif' # mask from IACS\n",
    "result_dir = '/data/fields/Auxiliary/grid_search/Brandenburg/' + predictions.split('/')[-1].split('.')[0] + '_' + reference.split('/')[-1].split('.')[0]\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "# set the number by which rows and cols will be divided --> determines the number of tiles // also set border limit (dont sample fields too close to tile borders) and sample size\n",
    "slicer = 10\n",
    "border_limit = 10\n",
    "sample_size  = 10000\n",
    "# set the number of cores for parallel processing and set seed\n",
    "ncores = 15\n",
    "np.random.seed(42)\n",
    "make_tifs_from_intermediate_step = False\n",
    "######### prepare job-list\n",
    "\n",
    "\n",
    "# create lists that will be passed on to the joblist\n",
    "tile_list = []\n",
    "extent_true_list = []\n",
    "extent_pred_list = []\n",
    "boundary_pred_list = []\n",
    "result_dir_list = []\n",
    "row_col_start = []\n",
    "\n",
    "\n",
    "# tile predictions in prds --> total extent encompasses 90 Force Tiles (+ a few rows and cols that will be neglected as they are outside of study area)\n",
    "pred_ds = gdal.Open(predictions)\n",
    "rows, cols = pred_ds.RasterYSize, pred_ds.RasterXSize\n",
    "\n",
    "row_start = [i for i in range(0, rows, math.floor(rows/slicer))]\n",
    "row_end = [i for i in range (math.floor(rows/slicer), rows, math.floor(rows/slicer))]\n",
    "row_start = row_start[:len(row_end)] \n",
    "\n",
    "col_start = [i for i in range(0, cols, math.floor(cols/slicer))]\n",
    "col_end = [i for i in range (math.floor(cols/slicer), cols, math.floor(cols/slicer))]\n",
    "col_start = col_start[:len(col_end)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c54035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load IACS reference mask and label it \n",
    "ref_ds = gdal.Open(reference)\n",
    "extent_true = ref_ds.GetRasterBand(1).ReadAsArray() \n",
    "binary_true = extent_true > 0\n",
    "instances_true = measure.label(binary_true, background=0, connectivity=1)\n",
    "\n",
    "# sample fields\n",
    "# build a mask to exclude fields that are in border_limit to tile borders\n",
    "power_mask = np.zeros(instances_true.shape)\n",
    "for i in range(len(row_end)):\n",
    "    for j in range(len(col_end)):\n",
    "            power_mask[row_start[i]:row_start[i] + border_limit, :] = 1\n",
    "            power_mask[:, col_start[j]:col_start[j] + border_limit] = 1\n",
    "            power_mask[row_end[-1] - border_limit:power_mask.shape[0], :] = 1\n",
    "            power_mask[:, col_end[-1] - border_limit:power_mask.shape[1]] = 1\n",
    "\n",
    "# makeTif_np_to_matching_tif(power_mask, reference, result_dir, 'powermask.tif',0)\n",
    "# get IDs from labelled reference\n",
    "IDs_to_skip = np.unique(instances_true[power_mask==1])\n",
    "\n",
    "# get distribution of field sizes after segmentation\n",
    "unique_IDs, counts = np.unique(instances_true, return_counts=True)\n",
    "\n",
    "# exlcude fields that are too close to tile borders\n",
    "mask = ~np.isin(unique_IDs, IDs_to_skip)\n",
    "unique_IDs = unique_IDs[mask]\n",
    "counts = counts[mask]\n",
    "\n",
    "if make_tifs_from_intermediate_step:\n",
    "    # Create filtered array with only valid IDs preserved for export\n",
    "    filtered_instances = np.where(np.isin(instances_true, unique_IDs), instances_true, 0)\n",
    "    makeTif_np_to_matching_tif(filtered_instances, reference, '/data/fields/output/predictions/FORCE/BRANDENBURG/auxiliary/256_20_chips_border_cut.tif')\n",
    "# exlude 0 (background) and 1 (super-small fields) from sample\n",
    "mask = (unique_IDs != 0) & (counts > 3)\n",
    "unique_IDs = unique_IDs[mask]\n",
    "counts = counts[mask]\n",
    "\n",
    "# get deciles and draw equally from them\n",
    "deciles = [perc for perc in range(10,100,10)]\n",
    "deciles_values = np.percentile(counts, deciles)\n",
    "decs = [0] + deciles_values.tolist() + [np.max(counts)]\n",
    "bin_ids = []\n",
    "for ind in range(len(decs) -1):\n",
    "    # get the unique_IDS of those fields, whose count (size) is within bin\n",
    "    bin_ids.append(np.random.choice(unique_IDs[(counts > decs[ind]) & (counts <= decs[ind + 1])], int(sample_size/10), replace=False))\n",
    "\n",
    "mask = np.isin(instances_true, np.concatenate(bin_ids))\n",
    "# set everything to 0 except samples\n",
    "instances_true[~mask] = 0\n",
    "\n",
    "if make_tifs_from_intermediate_step:\n",
    "    # Create filtered array with only valid IDs preserved for export\n",
    "    filtered_instances = np.where(np.isin(instances_true, unique_IDs), instances_true, 0)\n",
    "    makeTif_np_to_matching_tif(filtered_instances, reference, '/data/fields/output/predictions/FORCE/BRANDENBURG/auxiliary/256_20_chips_valid_IDs.tif', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in vrt in tiles\n",
    "for i in range(len(row_end)):\n",
    "    for j in range(len(col_end)):\n",
    "        \n",
    "        ######### fill the lists with tiled data\n",
    "\n",
    "        \n",
    "        #subset the prediction of fields read-in\n",
    "        extent_pred = pred_ds.GetRasterBand(1).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i]) # goes into InstSegm --> image of crop probability\n",
    "        # check if prediction subset of fields actually contains data\n",
    "        if len(np.unique(extent_pred)) == 1:\n",
    "            continue\n",
    "        # check if tile contains a sample of reference/label data\n",
    "        extent_true = instances_true[row_start[i]:row_end[i], col_start[j]:col_end[j]]\n",
    "        if len(np.unique(extent_true)) == 1:\n",
    "            continue\n",
    "        \n",
    "        extent_true_list.append(extent_true)\n",
    "        extent_pred_list.append(extent_pred)\n",
    "\n",
    "        # make identifier for tile for csv\n",
    "        tile_list.append(f'{str(i)}_{str(j)}')\n",
    "        # load predicted boundary prob subset // goes into InstSegm --> image of boundary probability\n",
    "        boundary_pred_list.append(pred_ds.GetRasterBand(2).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i])) \n",
    "        # output folder\n",
    "        result_dir_list.append(result_dir)\n",
    "        row_col_start.append(str(row_start[i]) + '_' + str(col_start[j]))\n",
    "\n",
    "jobs = [[tile_list[i], row_col_start[i] ,extent_true_list[i], extent_pred_list[i], boundary_pred_list[i], result_dir_list[i], border_limit]  for i in range(len(result_dir_list))]\n",
    "\n",
    "del tile_list, row_col_start, extent_true_list, extent_pred_list, boundary_pred_list, result_dir_list, border_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7747b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "\n",
    "row_col_start = jobs[ind][1]\n",
    "extent_true = jobs[ind][2]\n",
    "extent_pred = jobs[ind][3]\n",
    "boundary_pred = jobs[ind][4]\n",
    "t_ext=0.2\n",
    "t_bound=0.2\n",
    "border_limit=border_limit = jobs[ind][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ccc617",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_start = int(row_col_start.split('_')[0])\n",
    "col_start = int(row_col_start.split('_')[1])\n",
    "# get predicted instance segmentation\n",
    "instances_pred = InstSegm(extent_pred, boundary_pred, t_ext=t_ext, t_bound=t_bound)\n",
    "instances_pred = measure.label(instances_pred, background=-1) \n",
    "\n",
    "def export_intermediate_products(intermediate_aray, dummy_ds ,folder_out, filename):\n",
    "    '''\n",
    "    intermediate_aray: array to be exported\n",
    "    dummy_ds: a gdal.Open object that contains desired geoinformation\n",
    "    folder_out: path to FOLDER, where intermediate product will be stored\n",
    "    '''\n",
    "    if not folder_out.endswith('/'):\n",
    "        folder_out = folder_out + '/'\n",
    "    geoTF = dummy_ds.GetGeoTransform()\n",
    "    out_ds = gdal.GetDriverByName('GTiff').Create(f'{folder_out}{filename}', \n",
    "                                                instances_pred.shape[1], instances_pred.shape[0], 1, gdal.GDT_Int32)\n",
    "    # change the Geotransform for each chip\n",
    "    geotf = list(geoTF)\n",
    "    # get column and rows from filenames\n",
    "    geotf[0] = geotf[0] + geotf[1] * col_start\n",
    "    geotf[3] = geotf[3] + geotf[5] * row_start\n",
    "    #print(f'X:{geoTF[0]}  Y:{geoTF[3]}  AT {file}')\n",
    "    out_ds.SetGeoTransform(tuple(geotf))\n",
    "    out_ds.SetProjection(pred_ds.GetProjection())\n",
    "                \n",
    "    out_ds.GetRasterBand(1).WriteArray(intermediate_aray)\n",
    "\n",
    "    del out_ds\n",
    "\n",
    " intersecting_fields\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ccb505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4294967295"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc306fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get instances from ground truth label\n",
    "# binary_true = extent_true > 0\n",
    "# instances_true = measure.label(binary_true, background=0, connectivity=1)\n",
    "instances_true = extent_true\n",
    "\n",
    "# loop through true fields\n",
    "field_values = np.unique(instances_true)\n",
    "\n",
    "best_IoUs = []\n",
    "field_IDs = []\n",
    "field_sizes = []\n",
    "centroid_rows = []\n",
    "centroid_cols = []\n",
    "centroid_IoUS = []\n",
    "intersect_rows = []\n",
    "intersect_cols = []\n",
    "temp_rows = []\n",
    "temp_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c491dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for field_value in field_values:\n",
    "#     if field_value == 0:\n",
    "#         continue # move on to next value\n",
    "\n",
    "field_value = field_values[1]\n",
    "this_field = instances_true == field_value\n",
    "# # check if field is close to border and throw away if too close\n",
    "# if TooCloseToBorder(this_field, border_limit):\n",
    "#     continue\n",
    "\n",
    "# calculate centroid\n",
    "this_field_centroid = np.mean(np.column_stack(np.where(this_field)),axis=0).astype(int)\n",
    "\n",
    "# fill lists with info\n",
    "centroid_rows.append(this_field_centroid[0])\n",
    "centroid_cols.append(this_field_centroid[1])\n",
    "field_IDs.append(field_value)\n",
    "field_sizes.append(np.sum(this_field))\n",
    "\n",
    "# find predicted fields that intersect with true field\n",
    "intersecting_fields = this_field * instances_pred\n",
    "intersect_values = np.unique(intersecting_fields)\n",
    "\n",
    "# compute IoU for each intersecting field\n",
    "field_IoUs = []\n",
    "center_IoU = 0\n",
    "for intersect_value in intersect_values:\n",
    "    if intersect_value == 0:\n",
    "        continue # move on to next value\n",
    "    \n",
    "    pred_field = instances_pred == intersect_value\n",
    "    r, c = np.where(pred_field == True)\n",
    "    temp_rows.append(r + row_start)\n",
    "    temp_cols.append(c + col_start)\n",
    "    union = this_field + pred_field > 0\n",
    "    intersection = (this_field * pred_field) > 0\n",
    "    IoU = np.sum(intersection) / np.sum(union)\n",
    "    field_IoUs.append(IoU)\n",
    "    # check for centroid condition\n",
    "    if instances_pred[this_field_centroid[0], this_field_centroid[1]] == intersect_value:\n",
    "        center_IoU = IoU\n",
    "\n",
    "# # take maximum IoU - this is the IoU for this true field\n",
    "# if len(field_IoUs) != 0:\n",
    "#     best_IoUs.append(np.max(field_IoUs))\n",
    "#     # fill centroid list\n",
    "#     centroid_IoUS.append(center_IoU)\n",
    "#     max_index = np.argmax(field_IoUs)\n",
    "#     intersect_rows.append(temp_rows[max_index])\n",
    "#     intersect_cols.append(temp_cols[max_index])\n",
    "#     temp_rows = []\n",
    "#     temp_cols = []\n",
    "# else:\n",
    "#     best_IoUs.append(0)\n",
    "#     # fill centroid list\n",
    "#     centroid_IoUS.append(0)\n",
    "#     intersect_rows.append(0)\n",
    "#     intersect_cols.append(0)\n",
    "#     temp_rows = []\n",
    "#     temp_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dfe5b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1760, 1760, 1760, ..., 1910, 1911, 1911])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70cbe0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2690, 2997)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersecting_fields.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
