{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.8 (you have 1.4.13). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n"
     ]
    }
   ],
   "source": [
    "# import packages \n",
    "import sys\n",
    "\n",
    "sys.path.append('/media/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.feevos.rocksdbutils_copy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "F = 128\n",
    "s = F//2\n",
    "shape =(9000,9000)\n",
    "\n",
    "nTimesRows = int((shape[-2] - F)//s + 1)\n",
    "nTimesCols = int((shape[-1] - F)//s + 1)\n",
    "\n",
    "print(nTimesRows)\n",
    "print(nTimesCols)\n",
    "\n",
    "# Use these directly \n",
    "RowsCols = [(row, col) for row in range(nTimesRows-1) for col in range(nTimesCols-1)]\n",
    "RowsCols_Slices = [ (slice(row*s,row*s +F,1),slice(col*s,col*s+F,1) )  for (row,col) in RowsCols ]\n",
    "\n",
    "# Construct RowsCols for last Col \n",
    "col_rev = shape[-1]-F\n",
    "Rows4LastCol = [(row,col_rev) for row in range(nTimesRows-1)]\n",
    "Rows4LastCol_Slices = [ (slice(row*s,row*s +F,1),slice(col_rev,col_rev+F,1) )  for (row,col_rev) in Rows4LastCol]\n",
    "\n",
    "# Construct RowsCols for last Row \n",
    "row_rev = shape[-2]-F\n",
    "Cols4LastRow        = [(row_rev,col) for col in range(nTimesCols-1)]\n",
    "Cols4LastRow_Slices = [(slice(row_rev,row_rev+F,1),slice(col*s,col*s +F,1) )  for (row_rev,col) in Cols4LastRow]\n",
    "\n",
    "\n",
    "# Store all Rows and Columns that correspond to raster slices and slices \n",
    "RowsCols           = RowsCols + Rows4LastCol + Cols4LastRow\n",
    "RowsCols_Slices    = RowsCols_Slices + Rows4LastCol_Slices + Cols4LastRow_Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19320"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(RowsCols_Slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'AI4_RGB_exclude_False'\n",
    "\n",
    "#aa  = RocksDBDataset(f'/workspace/fields/output/rocks_db/{db_name}.db/train.db', transform=None)\n",
    "bb  = RocksDBDataset(f'/workspace/fields/output/rocks_db/{db_name}.db/valid.db', transform=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilelist(originpath, ftyp, deep = False, order = True):\n",
    "    out   = []\n",
    "    if deep == False:\n",
    "        files = os.listdir(originpath)\n",
    "        for i in files:\n",
    "            if i.split('.')[-1] in ftyp:\n",
    "                if originpath.endswith('/'):\n",
    "                    out.append(originpath + i)\n",
    "                else:\n",
    "                    out.append(originpath + '/' + i)\n",
    "            # else:\n",
    "            #     print(\"non-matching file - {} - found\".format(i.split('.')[-1]))\n",
    "    else:\n",
    "        for path, subdirs, files in os.walk(originpath):\n",
    "            for i in files:\n",
    "                if i.split('.')[-1] in ftyp:\n",
    "                    out.append(os.path.join(path, i))\n",
    "    if order == True:\n",
    "        out = sorted(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = aa.length\n",
    "valid = bb.length\n",
    "nc_len = len(getFilelist('/data/fields/ai4boundaries/sentinel2/images/', '.nc', deep=True))\n",
    "\n",
    "\n",
    "print(f'Training chips: {train}\\nValidation chips: {valid}\\nRatio: {train/(train+valid)}\\nRatio_chipped:{(train+valid)/nc_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(aa[0][0][1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'AI4_RGB_exclude_True'\n",
    "cc = RocksDBDataset(f'/data/fields/output/rocks_db/{db_name}.db/valid.db', transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_mask_to_prediction_extent(path_reference_mask, path_to_prediction_vrt):\n",
    "    '''\n",
    "    path_reference_mask: path to the reference mask\n",
    "    path_to_prediction_vrt: path to a vrt of the predicted image chips\n",
    "    '''\n",
    "\n",
    "    # check if mask has different extent from prediction\n",
    "    # if so, make it the same extent for further processing (classification)\n",
    "    # --> mask can never be smaller than prediciton, therefore no need to check\n",
    "\n",
    "    ext_mask = getExtentRas(path_reference_mask)\n",
    "    ext_pred = getExtentRas(path_to_prediction_vrt)\n",
    "\n",
    "    if ext_mask == ext_pred:\n",
    "        print('Mask already has same extent as prediction - no further subsetting needed :)')\n",
    "    else:\n",
    "        common_bounds = commonBoundsDim([ext_mask, ext_pred])\n",
    "        common_coords = commonBoundsCoord(common_bounds)\n",
    "        if common_bounds == ext_pred:\n",
    "            ds = gdal.Open(path_reference_mask)\n",
    "            in_gt = ds.GetGeoTransform()\n",
    "            inv_gt = gdal.InvGeoTransform(in_gt)\n",
    "            # transform coordinates into offsets (in cells) and make them integer\n",
    "            off_UpperLeft = gdal.ApplyGeoTransform(inv_gt, common_coords[0]['UpperLeftXY'][0], common_coords[0]['UpperLeftXY'][1])  # new UL * rastersize^-1  + original ul/rastersize(opposite sign\n",
    "            off_LowerRight = gdal.ApplyGeoTransform(inv_gt, common_coords[0]['LowerRightXY'][0], common_coords[0]['LowerRightXY'][1])\n",
    "            off_ULx, off_ULy = map(round, off_UpperLeft) \n",
    "            off_LRx, off_LRy = map(round, off_LowerRight)\n",
    "\n",
    "            band = ds.GetRasterBand(1)\n",
    "            data = band.ReadAsArray(off_ULx, off_ULy, off_LRx - off_ULx, off_LRy - off_ULy)\n",
    "\n",
    "\n",
    "            out_ds = gdal.GetDriverByName('GTiff').Create(path_reference_mask.split('.')[0] + '_prediction_extent.tif', \n",
    "                                                        off_LRx - off_ULx, \n",
    "                                                        off_LRy - off_ULy, 1, ds.GetRasterBand(1).DataType)\n",
    "            out_gt = list(in_gt)\n",
    "            out_gt[0], out_gt[3] = gdal.ApplyGeoTransform(in_gt, off_ULx, off_ULy)\n",
    "            out_ds.SetGeoTransform(out_gt)\n",
    "            out_ds.SetProjection(ds.GetProjection())\n",
    "\n",
    "            out_ds.GetRasterBand(1).WriteArray(data)\n",
    "            if band.GetNoDataValue():\n",
    "                out_ds.GetRasterBand(1).SetNoDataValue(band.GetNoDataValue())\n",
    "            del out_ds\n",
    "\n",
    "\n",
    "chipsize = 128*2 # 5 is the maximum with GPU in basement\n",
    "overlap  = 20\n",
    "\n",
    "# make a subset of the reference mask (extent FORCE output) to the extent of the prediction\n",
    "subset_mask_to_prediction_extent('/data/Aldhani/eoagritwin/fields/IACS/4_Crop_mask/GSA-DE_BRB-2019_cropMask_lines_touch_false_lines_touch_false_linecrop.tif', \n",
    "                                 f'/data/Aldhani/eoagritwin/fields/output/predictions/FORCE/BRANDENBURG/vrt/{chipsize}_{overlap}_chips.vrt')\n",
    "\n",
    "subset_mask_to_prediction_extent('/data/Aldhani/eoagritwin/fields/IACS/4_Crop_mask/GSA-DE_BRB-2019_cropMask_lines_touch_true_lines_touch_true_linecrop.tif', \n",
    "                                 f'/data/Aldhani/eoagritwin/fields/output/predictions/FORCE/BRANDENBURG/vrt/{chipsize}_{overlap}_chips.vrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "\n",
    "\n",
    "####################################################### Prepare\n",
    "\n",
    "# make vrts from force outputs for easier processing\n",
    "year = 2023\n",
    "list_of_forcefiles = reduce_force_to_validmonths(f'/data/force/output/BRANDENBURG/{year}/', 3, 8)\n",
    "ordered_forcetiles = force_order_BGRBNR(list_of_forcefiles)\n",
    "vrt_out_path = f'/data/fields/Auxiliary/vrt/{year}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "force_folder_name = get_forcetiles_range(list_of_forcefiles)\n",
    "if not vrt_out_path.endswith('/'):\n",
    "    vrt_out_path = vrt_out_path + '/'\n",
    "outDir = f'{vrt_out_path}{force_folder_name}/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ordered_forcetiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(outDir)\n",
    "print(outDir)\n",
    "for i in range(len(ordered_forcetiles[0])):\n",
    "    vrt = gdal.BuildVRT(f'{outDir}{force_folder_name}_{str(i)}.vrt', [tilefile[i] for tilefile in ordered_forcetiles], separate = False)\n",
    "    vrt = None\n",
    "print('single vrts created')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make paths in vrts relative\n",
    "vrts = getFilelist(outDir, '.vrt')\n",
    "for vrt in vrts:\n",
    "    convertVRTpathsTOrelative(vrt)\n",
    "nums = [int(vrt.split('_')[-1].split('.')[0]) for vrt in vrts]\n",
    "vrts_sorted = sortListwithOtherlist(nums, vrts)[-1]\n",
    "print('paths in vrts made relative')\n",
    "\n",
    "vrt = gdal.BuildVRT(f'{outDir}{force_folder_name}_Cube.vrt', vrts_sorted, separate = True)\n",
    "vrt = None\n",
    "# convertVRTpathsTOrelative(f'{outDir}{force_folder_name}_Cube.vrt')\n",
    "print('overlord vrt created')\n",
    "\n",
    "vrtPyramids(f'{outDir}{force_folder_name}_Cube.vrt')\n",
    "print('VRT created with pyramids')\n",
    "\n",
    "print('Vrt might already exist - please check!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
