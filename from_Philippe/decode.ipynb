{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import math\n",
    "import os\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import higra as hg\n",
    "import scipy.ndimage as si\n",
    "from skimage import measure\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTif_np_to_matching_tif(array, tif_path, out_folder, ending):\n",
    "    ds = gdal.Open(tif_path)\n",
    "    gtiff_driver = gdal.GetDriverByName('GTiff')\n",
    "    file_name = tif_path.split('/')[-1].split('.')[0]\n",
    "    out_ds = gtiff_driver.Create(f'{out_folder}/{file_name}{ending}',ds.RasterXSize, ds.RasterYSize, 1, gdal.GDT_Float32)\n",
    "    out_ds.SetGeoTransform(ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(ds.GetProjection())             \n",
    "    out_ds.GetRasterBand(1).WriteArray(array)\n",
    "    del out_ds\n",
    "\n",
    "def TooCloseToBorder(numbered_array, border_limit):\n",
    "    rows, cols = np.where(numbered_array==True)\n",
    "    r,c = numbered_array.shape\n",
    "    if any(value < border_limit for value in [np.min(rows), r - np.max(rows), np.min(cols), c - np.max(cols)]):\n",
    "        return True\n",
    "def InstSegm(extent, boundary, t_ext=0.4, t_bound=0.2):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "    extent : extent prediction\n",
    "    boundary : boundary prediction\n",
    "    t_ext : threshold for extent\n",
    "    t_bound : threshold for boundary\n",
    "    OUTPUT:\n",
    "    instances\n",
    "    \"\"\"\n",
    "\n",
    "    # Threshold extent mask\n",
    "    ext_binary = np.uint8(extent >= t_ext)\n",
    "\n",
    "    # Artificially create strong boundaries for\n",
    "    # pixels with non-field labels\n",
    "    input_hws = np.copy(boundary)\n",
    "    input_hws[ext_binary == 0] = 1\n",
    "\n",
    "    # Create the directed graph\n",
    "    size = input_hws.shape[:2]\n",
    "    graph = hg.get_8_adjacency_graph(size)\n",
    "    edge_weights = hg.weight_graph(\n",
    "        graph,\n",
    "        input_hws,\n",
    "        hg.WeightFunction.mean\n",
    "    )\n",
    "\n",
    "    tree, altitudes = hg.watershed_hierarchy_by_dynamics(\n",
    "        graph,\n",
    "        edge_weights\n",
    "    )\n",
    "    \n",
    "    # Get individual fields\n",
    "    # by cutting the graph using altitude\n",
    "    instances = hg.labelisation_horizontal_cut_from_threshold(\n",
    "        tree,\n",
    "        altitudes,\n",
    "        threshold=t_bound)\n",
    "    \n",
    "    instances[ext_binary == 0] = -1\n",
    "\n",
    "    return instances\n",
    "\n",
    "def get_IoUs(extent_true, extent_pred, boundary_pred, t_ext=0.4, \n",
    "             t_bound=0.2, plot=False, sample_size=0.05, border_limit=10):\n",
    "\n",
    "    # get predicted instance segmentation\n",
    "    instances_pred = InstSegm(extent_pred, boundary_pred, t_ext=t_ext, t_bound=t_bound)\n",
    "    instances_pred = measure.label(instances_pred, background=-1) \n",
    "    \n",
    "    # get instances from ground truth label\n",
    "    binary_true = extent_true > 0\n",
    "    instances_true = measure.label(binary_true, background=0, connectivity=1)\n",
    "   \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "        ax[0].imshow(instances_true)\n",
    "        ax[1].imshow(instances_pred)\n",
    "        plt.show()\n",
    "    \n",
    "    # loop through true fields\n",
    "    field_values = np.unique(instances_true)\n",
    "    # here subsetting\n",
    "    field_values = np.random.choice(field_values, size=int(sample_size * len(field_values)), replace=False)\n",
    "\n",
    "    best_IoUs = []\n",
    "    field_IDs = []\n",
    "    field_sizes = []\n",
    "    centroid_rows = []\n",
    "    centroid_cols = []\n",
    "    centroid_IoUS = []\n",
    "\n",
    "    for field_value in field_values:\n",
    "        if field_value == 0:\n",
    "            continue # move on to next value\n",
    "    \n",
    "        this_field = instances_true == field_value\n",
    "        # check if field is close to border and throw away if too close\n",
    "        if TooCloseToBorder(this_field, border_limit):\n",
    "            continue\n",
    "\n",
    "        # calculate centroid\n",
    "        this_field_centroid = np.mean(np.column_stack(np.where(this_field)),axis=0).astype(int)\n",
    "        \n",
    "        # fill lists with info\n",
    "        centroid_rows.append(this_field_centroid[0])\n",
    "        centroid_cols.append(this_field_centroid[1])\n",
    "        field_IDs.append(field_value)\n",
    "        field_sizes.append(np.sum(this_field))\n",
    "        \n",
    "        # find predicted fields that intersect with true field\n",
    "        intersecting_fields = this_field * instances_pred\n",
    "        intersect_values = np.unique(intersecting_fields)\n",
    "        intersect_fields = np.isin(instances_pred, intersect_values[1:])\n",
    "        \n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "            ax[0].imshow(this_field)\n",
    "            ax[1].imshow(intersect_fields)\n",
    "            plt.show()\n",
    "        \n",
    "        # compute IoU for each intersecting field\n",
    "        field_IoUs = []\n",
    "        for intersect_value in intersect_values:\n",
    "            if intersect_value == 0 or (len(np.unique(intersect_values)) == 1 and intersect_value == 0):\n",
    "                continue # move on to next value\n",
    "            \n",
    "            pred_field = instances_pred == intersect_value\n",
    "            union = this_field + pred_field > 0\n",
    "            intersection = (this_field * pred_field) > 0\n",
    "            IoU = np.sum(intersection) / np.sum(union)\n",
    "            field_IoUs.append(IoU)\n",
    "            # fill the centroid condition\n",
    "            if instances_pred[this_field_centroid[0], this_field_centroid[1]] == intersect_value:\n",
    "                centroid_IoUS.append(IoU)\n",
    "    \n",
    "        # take maximum IoU - this is the IoU for this true field\n",
    "        best_IoUs.append(np.max(field_IoUs))\n",
    "   \n",
    "    return best_IoUs, centroid_IoUS, field_IDs, field_sizes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the predictions and labels\n",
    "\n",
    "predictions =  '/data/fields/output/predictions/FORCE/BRANDENBURG/vrt/256_20_masked_chipsvrt.vrt' # predictions straight from GPU \n",
    "reference =  '/data/fields/IACS/Auxiliary/GSA-DE_BRB-2019_All_agromask_linecrop_prediction_extent.tif' # mask from IACS\n",
    "\n",
    "result_dir = '/data/fields/Auxiliary/grid_search/' + predictions.split('/')[-1].split('.')[0] + '_' + reference.split('/')[-1].split('.')[0]\n",
    "\n",
    "# make a dictionary for export\n",
    "k = ['tile','t_ext','t_bound', 'max_IoU', 'centroid_IoU', 'field_IDs', 'field_sizes'] #'medianIoU', 'meanIoU', 'IoU_50', 'IoU_80']\n",
    "v = [list() for i in range(len(k))]\n",
    "res = dict(zip(k, v))\n",
    "\n",
    "\n",
    "# tile predictions in prds --> total extent encompasses 90 Force Tiles (+ a few rows and cols that will be neglected as they are outside of study area)\n",
    "pred_ds = gdal.Open(predictions)\n",
    "rows, cols = pred_ds.RasterYSize, pred_ds.RasterXSize\n",
    "tiles = 10\n",
    "\n",
    "row_start = [i for i in range(0, rows, math.floor(rows/tiles))]\n",
    "row_end = [i for i in range (math.floor(rows/tiles), rows, math.floor(rows/tiles))]\n",
    "row_start = row_start[:len(row_end)] \n",
    "\n",
    "col_start = [i for i in range(0, cols, math.floor(cols/tiles))]\n",
    "col_end = [i for i in range (math.floor(cols/tiles), cols, math.floor(cols/tiles))]\n",
    "col_start = col_start[:len(col_end)] \n",
    "\n",
    "# read in vrt in tiles\n",
    "for i in [6]:# range(len(row_end)):\n",
    "\n",
    "    print(f'Starting on {i+1}. row from {len(row_end)} rows')\n",
    "    \n",
    "    for j in [3]:# range(len(col_end)):\n",
    "        \n",
    "        print(f'Starting on {j+1}.column from {len(col_end)} columns')\n",
    "        # make identifier for tile for csv\n",
    "        tile = f'{str(i)}_{str(j)}'\n",
    "        #s ubset the prediction of fields read-in\n",
    "        extent_pred = pred_ds.GetRasterBand(1).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i]) # goes into InstSegm --> image of crop probability\n",
    "        # check if prediction subset of fields actually contains data\n",
    "        if len(np.unique(extent_pred)) == 1:\n",
    "            continue\n",
    "        # load predicted boundary prob subset\n",
    "        boundary_pred = pred_ds.GetRasterBand(2).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i]) # goes into InstSegm --> image of boundary probability\n",
    "        # load IACS reference\n",
    "        ref_ds = gdal.Open(reference)\n",
    "        extent_true = ref_ds.GetRasterBand(1).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i]) # goes into InstSegm --> image of crop probability\n",
    "        \n",
    "        # set the parameter combinations and test combinations\n",
    "        t_exts = [i/100 for i in range(10,55,5)] \n",
    "        t_bounds = [i/100 for i in range(10,55,5)]\n",
    "\n",
    "        for t_ext in t_exts:\n",
    "            for t_bound in t_bounds:\n",
    "                print('thresholds: ' + str(t_ext) + ', ' +str(t_bound))\n",
    "\n",
    "                img_IoUs, centroid_IoUS, field_IDs, field_sizes = get_IoUs(extent_true, extent_pred, boundary_pred, t_ext=t_ext, t_bound=t_bound,\n",
    "                                    sample_size=0.01 ,border_limit=10)\n",
    "              \n",
    "                for e, IoUs in enumerate(img_IoUs):\n",
    "                    res['tile'].append(tile)\n",
    "                    res['t_ext'].append(t_ext)\n",
    "                    res['t_bound'].append(t_bound)\n",
    "                    res['max_IoU'].append(IoUs)\n",
    "                    res['centroid_IoU'].append(centroid_IoUS[e])\n",
    "                    res['field_IDs'].append(field_IDs[e])\n",
    "                    res['field_sizes'].append(field_sizes[e])\n",
    "       \n",
    "df  = pd.DataFrame(data = res)\n",
    "df.to_csv(result_dir + '_IoU_hyperparameter_tuning_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted instance segmentation\n",
    "instances_pred = InstSegm(extent_pred, boundary_pred, t_ext=t_ext, t_bound=t_bound)\n",
    "instances_pred = measure.label(instances_pred, background=-1) # shouldn't that be 0\n",
    "    \n",
    "# get instances from ground truth label\n",
    "binary_true = extent_true > 0\n",
    "instances_true = measure.label(binary_true, background=0, connectivity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through true fields\n",
    "field_values = np.unique(instances_true)\n",
    "# here subsetting\n",
    "field_values = np.random.choice(field_values, size=int(0.1 * len(field_values)), replace=False)\n",
    "\n",
    "best_IoUs = []\n",
    "field_IDs = []\n",
    "field_sizes = []\n",
    "centroid_rows = []\n",
    "centroid_cols = []\n",
    "centroid_IoUS = []\n",
    "\n",
    "field_value = field_values[4]\n",
    "print(field_value)\n",
    "this_field = instances_true == field_value\n",
    "# check if field is close to border and throw away if too close\n",
    "\n",
    "# create centroid\n",
    "this_field_centroid = np.mean(np.column_stack(np.where(this_field)),axis=0).astype(int)\n",
    "# fill lists with info\n",
    "centroid_rows.append(this_field_centroid[0])\n",
    "centroid_cols.append(this_field_centroid[1])\n",
    "field_IDs.append(field_value)\n",
    "field_sizes.append(np.sum(this_field))\n",
    "\n",
    "# find predicted fields that intersect with true field\n",
    "intersecting_fields = this_field * instances_pred\n",
    "intersect_values = np.unique(intersecting_fields)\n",
    "intersect_fields = np.isin(instances_pred, intersect_values[1:])\n",
    "\n",
    "# compute IoU for each intersecting field\n",
    "field_IoUs = []\n",
    "for intersect_value in intersect_values:\n",
    "    if intersect_value == 0 or (len(np.unique(intersect_values)) == 1 and intersect_value == 0):\n",
    "        continue # move on to next value\n",
    "    \n",
    "    pred_field = instances_pred == intersect_value\n",
    "    union = this_field + pred_field > 0\n",
    "    intersection = (this_field * pred_field) > 0\n",
    "    IoU = np.sum(intersection) / np.sum(union)\n",
    "    if instances_pred[this_field_centroid[0], this_field_centroid[1]] == intersect_value:\n",
    "        centroid_IoUS.append(IoU)\n",
    "    field_IoUs.append(IoU)\n",
    "\n",
    "# # take maximum IoU - this is the IoU for this true field\n",
    "# if len(field_IoUs) > 0:\n",
    "#     best_IoUs.append(np.max(field_IoUs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4010\n",
      "4010\n"
     ]
    }
   ],
   "source": [
    "for intersect in intersect_values:\n",
    "    if instances_pred[this_field_centroid[0], this_field_centroid[1]] == intersect:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2690, 2997)\n",
      "(2690, 2997)\n",
      "[2242 2715]\n"
     ]
    }
   ],
   "source": [
    "print(instances_pred.shape)\n",
    "print(instances_true.shape)\n",
    "print(this_field_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2242, 2715])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.column_stack(np.where(this_field)),axis=0).astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
