{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import math\n",
    "import os\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import higra as hg\n",
    "import scipy.ndimage as si\n",
    "from skimage import measure\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InstSegm(extent, boundary, t_ext=0.4, t_bound=0.2):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "    extent : extent prediction\n",
    "    boundary : boundary prediction\n",
    "    t_ext : threshold for extent\n",
    "    t_bound : threshold for boundary\n",
    "    OUTPUT:\n",
    "    instances\n",
    "    \"\"\"\n",
    "\n",
    "    # Threshold extent mask\n",
    "    ext_binary = np.uint8(extent >= t_ext)\n",
    "\n",
    "    # Artificially create strong boundaries for\n",
    "    # pixels with non-field labels\n",
    "    input_hws = np.copy(boundary)\n",
    "    input_hws[ext_binary == 0] = 1\n",
    "\n",
    "    # Create the directed graph\n",
    "    size = input_hws.shape[:2]\n",
    "    graph = hg.get_8_adjacency_graph(size)\n",
    "    edge_weights = hg.weight_graph(\n",
    "        graph,\n",
    "        input_hws,\n",
    "        hg.WeightFunction.mean\n",
    "    )\n",
    "\n",
    "    tree, altitudes = hg.watershed_hierarchy_by_dynamics(\n",
    "        graph,\n",
    "        edge_weights\n",
    "    )\n",
    "    \n",
    "    # Get individual fields\n",
    "    # by cutting the graph using altitude\n",
    "    instances = hg.labelisation_horizontal_cut_from_threshold(\n",
    "        tree,\n",
    "        altitudes,\n",
    "        threshold=t_bound)\n",
    "    \n",
    "    instances[ext_binary == 0] = -1\n",
    "\n",
    "    return instances\n",
    "\n",
    "def get_IoUs(extent_true, extent_pred, boundary_pred, t_ext=0.4, \n",
    "             t_bound=0.2, plot=False, sample_size=0.1, border_limit=10):\n",
    "    \n",
    "    # get predicted instance segmentation\n",
    "    instances_pred = InstSegm(extent_pred, boundary_pred, t_ext=t_ext, t_bound=t_bound)\n",
    "    print('instsegm done')\n",
    "    instances_pred = measure.label(instances_pred, background=-1) # shouldn't that be 0\n",
    "    print('pred number done')\n",
    "    # get instances from ground truth label\n",
    "    binary_true = extent_true > 0\n",
    "    instances_true = measure.label(binary_true, background=0, connectivity=1)\n",
    "   \n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "        ax[0].imshow(instances_true)\n",
    "        ax[1].imshow(instances_pred)\n",
    "        plt.show()\n",
    "    \n",
    "    # loop through true fields\n",
    "    field_values = np.unique(instances_true)\n",
    "    # here subsetting\n",
    "    sample_size = 0.1\n",
    "    field_values = np.random.choice(field_values, size=int(sample_size * len(field_values)), replace=False)\n",
    "\n",
    "    best_IoUs = []\n",
    "    field_sizes = []\n",
    "    \n",
    "    for field_value in field_values:\n",
    "        if field_value == 0:\n",
    "            continue # move on to next value\n",
    "            \n",
    "        this_field = instances_true == field_value\n",
    "        # check if field is close to border and throw away if too close\n",
    "        if TooCloseToBorder(this_field, border_limit):\n",
    "            print('too close')\n",
    "            continue\n",
    "        field_sizes.append(np.sum(this_field))\n",
    "        \n",
    "        # find predicted fields that intersect with true field\n",
    "        intersecting_fields = this_field * instances_pred\n",
    "        intersect_values = np.unique(intersecting_fields)\n",
    "        print(len(intersect_values))\n",
    "        intersect_fields = np.isin(instances_pred, intersect_values[1:])\n",
    "        \n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "            ax[0].imshow(this_field)\n",
    "            ax[1].imshow(intersect_fields)\n",
    "            plt.show()\n",
    "        \n",
    "        # compute IoU for each intersecting field\n",
    "        field_IoUs = []\n",
    "        for intersect_value in intersect_values:\n",
    "            if intersect_value == 0:\n",
    "                continue # move on to next value\n",
    "            pred_field = instances_pred == intersect_value\n",
    "            union = this_field + pred_field > 0\n",
    "            intersection = (this_field * pred_field) > 0\n",
    "            IoU = np.sum(intersection) / np.sum(union)\n",
    "            field_IoUs.append(IoU)\n",
    "    \n",
    "        # take maximum IoU - this is the IoU for this true field\n",
    "        if len(field_IoUs) > 0:\n",
    "            best_IoUs.append(np.max(field_IoUs))\n",
    "        else:\n",
    "            best_IoUs.append(0)\n",
    "    \n",
    "    return best_IoUs, field_sizes\n",
    "\n",
    "def makeTif_np_to_matching_tif(array, tif_path, out_folder, ending):\n",
    "    ds = gdal.Open(tif_path)\n",
    "    gtiff_driver = gdal.GetDriverByName('GTiff')\n",
    "    file_name = tif_path.split('/')[-1].split('.')[0]\n",
    "    out_ds = gtiff_driver.Create(f'{out_folder}/{file_name}{ending}',ds.RasterXSize, ds.RasterYSize, 1, gdal.GDT_Float32)\n",
    "    out_ds.SetGeoTransform(ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(ds.GetProjection())             \n",
    "    out_ds.GetRasterBand(1).WriteArray(array)\n",
    "    del out_ds\n",
    "\n",
    "def TooCloseToBorder(numbered_array, border_limit):\n",
    "    rows, cols = np.where(numbered_array==True)\n",
    "    r,c = this_field.shape\n",
    "    if any(value < border_limit for value in [np.min(rows), r - np.max(rows), np.min(cols), c - np.max(cols)]):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on 1. row from 10 rows\n",
      "Starting on 1.column from 10 columns\n",
      "Starting on 2.column from 10 columns\n",
      "Starting on 3.column from 10 columns\n",
      "Starting on 4.column from 10 columns\n",
      "Starting on 5.column from 10 columns\n",
      "Starting on 6.column from 10 columns\n",
      "Starting on 7.column from 10 columns\n",
      "instsegm done\n",
      "pred number done\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "instsegm done\n",
      "pred number done\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "instsegm done\n",
      "pred number done\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "instsegm done\n",
      "pred number done\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "instsegm done\n",
      "pred number done\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "instsegm done\n",
      "pred number done\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "instsegm done\n",
      "pred number done\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "instsegm done\n",
      "pred number done\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "instsegm done\n",
      "pred number done\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "instsegm done\n",
      "pred number done\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n",
      "too close\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 65\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t_ext \u001b[38;5;129;01min\u001b[39;00m t_exts:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t_bound \u001b[38;5;129;01min\u001b[39;00m t_bounds:\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;66;03m# print('thresholds: ' + str(t_ext) + ', ' +str(t_bound))\u001b[39;00m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;66;03m#IoUs = []\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# extent_pred = np.squeeze(prediction[0]) # goes into InstSegm --> image of crop probability\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;66;03m# boundary_pred = np.squeeze(prediction[1]) # goes into InstSegm --> image of boundary probability\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m         img_IoUs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_IoUs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextent_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextent_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_ext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_ext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_bound\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;66;03m#img_IoUs, _ = get_IoUs_scores(extent_true, extent_pred, boundary_pred, t_ext=t_ext, t_bound=t_bound, t_semc=t_semc)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;66;03m#IoUs = IoUs + img_IoUs\u001b[39;00m\n\u001b[1;32m     69\u001b[0m         res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtile\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(j)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[158], line 49\u001b[0m, in \u001b[0;36mget_IoUs\u001b[0;34m(extent_true, extent_pred, boundary_pred, t_ext, t_bound, plot, sample_size, border_limit)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_IoUs\u001b[39m(extent_true, extent_pred, boundary_pred, t_ext\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, \n\u001b[1;32m     46\u001b[0m              t_bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, border_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     47\u001b[0m     \n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# get predicted instance segmentation\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     instances_pred \u001b[38;5;241m=\u001b[39m \u001b[43mInstSegm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextent_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_ext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_ext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_bound\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstsegm done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m     instances_pred \u001b[38;5;241m=\u001b[39m measure\u001b[38;5;241m.\u001b[39mlabel(instances_pred, background\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# shouldn't that be 0\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[158], line 29\u001b[0m, in \u001b[0;36mInstSegm\u001b[0;34m(extent, boundary, t_ext, t_bound)\u001b[0m\n\u001b[1;32m     22\u001b[0m graph \u001b[38;5;241m=\u001b[39m hg\u001b[38;5;241m.\u001b[39mget_8_adjacency_graph(size)\n\u001b[1;32m     23\u001b[0m edge_weights \u001b[38;5;241m=\u001b[39m hg\u001b[38;5;241m.\u001b[39mweight_graph(\n\u001b[1;32m     24\u001b[0m     graph,\n\u001b[1;32m     25\u001b[0m     input_hws,\n\u001b[1;32m     26\u001b[0m     hg\u001b[38;5;241m.\u001b[39mWeightFunction\u001b[38;5;241m.\u001b[39mmean\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m tree, altitudes \u001b[38;5;241m=\u001b[39m \u001b[43mhg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwatershed_hierarchy_by_dynamics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_weights\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Get individual fields\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# by cutting the graph using altitude\u001b[39;00m\n\u001b[1;32m     36\u001b[0m instances \u001b[38;5;241m=\u001b[39m hg\u001b[38;5;241m.\u001b[39mlabelisation_horizontal_cut_from_threshold(\n\u001b[1;32m     37\u001b[0m     tree,\n\u001b[1;32m     38\u001b[0m     altitudes,\n\u001b[1;32m     39\u001b[0m     threshold\u001b[38;5;241m=\u001b[39mt_bound)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/higra/hierarchy/watershed_hierarchy.py:109\u001b[0m, in \u001b[0;36mwatershed_hierarchy_by_dynamics\u001b[0;34m(graph, edge_weights, canonize_tree)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwatershed_hierarchy_by_dynamics\u001b[39m(graph, edge_weights, canonize_tree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    Watershed hierarchy by dynamics.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m             and its node altitudes\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwatershed_hierarchy_by_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maltitudes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mhg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute_dynamics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43maltitudes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mincreasing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcanonize_tree\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/higra/hierarchy/watershed_hierarchy.py:220\u001b[0m, in \u001b[0;36mwatershed_hierarchy_by_attribute\u001b[0;34m(graph, edge_weights, attribute_functor, canonize_tree)\u001b[0m\n\u001b[1;32m    216\u001b[0m     hg\u001b[38;5;241m.\u001b[39mCptHierarchy\u001b[38;5;241m.\u001b[39mlink(tree, graph)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attribute_functor(tree, altitudes)\n\u001b[0;32m--> 220\u001b[0m tree, altitudes, mst_edge_map \u001b[38;5;241m=\u001b[39m \u001b[43mhg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_watershed_hierarchy_by_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhelper_functor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m hg\u001b[38;5;241m.\u001b[39mCptHierarchy\u001b[38;5;241m.\u001b[39mlink(tree, graph)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m canonize_tree:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/higra/hierarchy/watershed_hierarchy.py:218\u001b[0m, in \u001b[0;36mwatershed_hierarchy_by_attribute.<locals>.helper_functor\u001b[0;34m(tree, altitudes)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhelper_functor\u001b[39m(tree, altitudes):\n\u001b[1;32m    216\u001b[0m     hg\u001b[38;5;241m.\u001b[39mCptHierarchy\u001b[38;5;241m.\u001b[39mlink(tree, graph)\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mattribute_functor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maltitudes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/higra/hierarchy/watershed_hierarchy.py:111\u001b[0m, in \u001b[0;36mwatershed_hierarchy_by_dynamics.<locals>.<lambda>\u001b[0;34m(tree, altitudes)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwatershed_hierarchy_by_dynamics\u001b[39m(graph, edge_weights, canonize_tree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    Watershed hierarchy by dynamics.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m             and its node altitudes\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m watershed_hierarchy_by_attribute(graph, edge_weights,\n\u001b[1;32m    110\u001b[0m                                             \u001b[38;5;28;01mlambda\u001b[39;00m tree, altitudes:\n\u001b[0;32m--> 111\u001b[0m                                             \u001b[43mhg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute_dynamics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43maltitudes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mincreasing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    114\u001b[0m                                             canonize_tree)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/higra/data_cache.py:550\u001b[0m, in \u001b[0;36mauto_cache.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m     h \u001b[38;5;241m=\u001b[39m __make_hash(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_recompute \u001b[38;5;129;01mor\u001b[39;00m h \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m--> 550\u001b[0m         cache[h] \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[h]\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;66;03m# cannot cache obj...\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/higra/attribute/tree_attributes.py:546\u001b[0m, in \u001b[0;36mattribute_dynamics\u001b[0;34m(tree, altitudes, increasing_altitudes)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03mGiven a node :math:`n` of the tree :math:`T`, the dynamics of :math:`n` is the difference between\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03mthe altitude of the deepest minima of the subtree rooted in :math:`n` and the altitude\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m:return: a 1d array like :attr:`altitudes`\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    544\u001b[0m inc \u001b[38;5;241m=\u001b[39m __process_param_increasing_altitudes(tree, altitudes, increasing_altitudes)\n\u001b[0;32m--> 546\u001b[0m height \u001b[38;5;241m=\u001b[39m \u001b[43mhg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute_height\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maltitudes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hg\u001b[38;5;241m.\u001b[39mattribute_extinction_value(tree, altitudes, height, inc)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/higra/data_cache.py:550\u001b[0m, in \u001b[0;36mauto_cache.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m     h \u001b[38;5;241m=\u001b[39m __make_hash(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_recompute \u001b[38;5;129;01mor\u001b[39;00m h \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m--> 550\u001b[0m         cache[h] \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[h]\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;66;03m# cannot cache obj...\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/higra/attribute/tree_attributes.py:511\u001b[0m, in \u001b[0;36mattribute_height\u001b[0;34m(tree, altitudes, increasing_altitudes)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;124;03mIn a tree :math:`T`, given that the altitudes of the nodes vary monotically from the leaves to the root,\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03mthe height of a node :math:`n` of :math:`T` is equal to the difference between the altitude of the parent\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m:return: a 1d array like :attr:`altitudes`\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m inc \u001b[38;5;241m=\u001b[39m __process_param_increasing_altitudes(tree, altitudes, increasing_altitudes)\n\u001b[0;32m--> 511\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mhg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute_height\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maltitudes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load the predictions and labels\n",
    "\n",
    "predictions =  '/data/fields/output/predictions/FORCE/BRANDENBURG/vrt/256_20_masked_chipsvrt.vrt' # predictions straight from GPU \n",
    "reference =  '/data/fields/IACS/Auxiliary/GSA-DE_BRB-2019_All_agromask_linecrop_prediction_extent.tif' # mask from IACS\n",
    "\n",
    "\n",
    "result_dir = '/data/fields/Auxiliary/grid_search/' + predictions.split('/')[-1].split('.')[0] + '_' + reference.split('/')[-1].split('.')[0]\n",
    "\n",
    "# make a dictionary for export\n",
    "k = ['tile','t_ext','t_bound', 'IoU'] #'medianIoU', 'meanIoU', 'IoU_50', 'IoU_80']\n",
    "v = [list() for i in range(len(k))]\n",
    "res = dict(zip(k, v))\n",
    "# mIoUs = []\n",
    "# mnIoUs = []\n",
    "# IoU_50s = []\n",
    "# IoU_80s = []\n",
    "\n",
    "\n",
    "# tile predictions in prds --> total extent encompasses 90 Force Tiles (+ a few rows and cols that will be neglected as they are outside of study area)\n",
    "pred_ds = gdal.Open(predictions)\n",
    "rows, cols = pred_ds.RasterYSize, pred_ds.RasterXSize\n",
    "tiles = 10\n",
    "\n",
    "row_start = [i for i in range(0, rows, math.floor(rows/tiles))]\n",
    "row_end = [i for i in range (math.floor(rows/tiles), rows, math.floor(rows/tiles))]\n",
    "row_start = row_start[:len(row_end)] \n",
    "\n",
    "col_start = [i for i in range(0, cols, math.floor(cols/tiles))]\n",
    "col_end = [i for i in range (math.floor(cols/tiles), cols, math.floor(cols/tiles))]\n",
    "col_start = col_start[:len(col_end)] \n",
    "\n",
    "# read in vrt in tiles\n",
    "for i in range(len(row_end)):\n",
    "\n",
    "    print(f'Starting on {i+1}. row from {len(row_end)} rows')\n",
    "    \n",
    "    for j in range(len(col_end)):\n",
    "\n",
    "        print(f'Starting on {j+1}.column from {len(col_end)} columns')\n",
    "        extent_pred = pred_ds.GetRasterBand(1).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i]) # goes into InstSegm --> image of crop probability\n",
    "        # check if it actually contains data\n",
    "        if len(np.unique(extent_pred)) == 1:\n",
    "            continue\n",
    "\n",
    "        boundary_pred = pred_ds.GetRasterBand(2).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i]) # goes into InstSegm --> image of boundary probability\n",
    "        ref_ds = gdal.Open(reference)\n",
    "        extent_true = ref_ds.GetRasterBand(1).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i]) # goes into InstSegm --> image of crop probability\n",
    "        \n",
    "        # set the parameter combinations and test combinations\n",
    "        t_exts = [i/100 for i in range(10,55,5)] \n",
    "        t_bounds = [i/100 for i in range(10,55,5)]\n",
    "\n",
    "        for t_ext in t_exts:\n",
    "            for t_bound in t_bounds:\n",
    "                # print('thresholds: ' + str(t_ext) + ', ' +str(t_bound))\n",
    "                #IoUs = []\n",
    "\n",
    "                # reference = gdal.Open(refs[i]).ReadAsArray()\n",
    "                # extent_true = np.squeeze(reference[0])\n",
    "\n",
    "                # prediction = gdal.Open(prds[i]).ReadAsArray()\n",
    "                # extent_pred = np.squeeze(prediction[0]) # goes into InstSegm --> image of crop probability\n",
    "                # boundary_pred = np.squeeze(prediction[1]) # goes into InstSegm --> image of boundary probability\n",
    "\n",
    "                img_IoUs, _ = get_IoUs(extent_true, extent_pred, boundary_pred, t_ext=t_ext, t_bound=t_bound)\n",
    "                #img_IoUs, _ = get_IoUs_scores(extent_true, extent_pred, boundary_pred, t_ext=t_ext, t_bound=t_bound, t_semc=t_semc)\n",
    "                #IoUs = IoUs + img_IoUs\n",
    "\n",
    "                res['tile'].append(f'{str(i)}_{str(j)}')\n",
    "                res['t_ext'].append(t_ext)\n",
    "                res['t_bound'].append(t_bound)\n",
    "                res['IoU'].append(img_IoUs)\n",
    "                # res['medianIoU'].append(np.median(IoUs))\n",
    "                # res['meanIoU'].append(np.mean(IoUs))\n",
    "                # res['IoU_50'].append(np.sum(np.array(IoUs) > 0.5) / len(IoUs))\n",
    "                # res['IoU_80'].append(np.sum(np.array(IoUs) > 0.8) / len(IoUs))\n",
    "                # mIoUs.append(np.median(IoUs))\n",
    "                # mnIoUs.append(np.mean(IoUs))\n",
    "                # IoU_50s.append(np.sum(np.array(IoUs) > 0.5) / len(IoUs))\n",
    "                # IoU_80s.append(np.sum(np.array(IoUs) > 0.8) / len(IoUs))\n",
    "\n",
    "# # hp_df = pd.DataFrame({\n",
    "# #     't_ext': np.repeat(t_exts, len(t_bounds)),\n",
    "# #     't_bound': np.tile(t_bounds, len(t_exts)),\n",
    "# #     'medianIoU': mIoUs,\n",
    "# #     'meanIoU': mnIoUs,\n",
    "# #     'IoU_50': IoU_50s,\n",
    "# #     'IoU_80': IoU_80s\n",
    "# # })\n",
    "# # hp_df.to_csv(os.path.join(results_dir, 'IoU_hyperparameter_tuning_full.csv'), index=False)\n",
    "res.to_csv(result_dir + '_IoU_hyperparameter_tuning_full.csv', index=False)\n",
    "print(res.iloc[res['meanIoU'].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "def TooCloseToBorder(numbered_array, border_limit):\n",
    "    rows, cols = np.where(numbered_array==True)\n",
    "    r,c = this_field.shape\n",
    "    if any(value < border_limit for value in [np.min(rows), r - np.max(rows), np.min(cols), c - np.max(cols)]):\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 333)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_field.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
