{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import math\n",
    "import os\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import higra as hg\n",
    "import scipy.ndimage as si\n",
    "from skimage import measure\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InstSegm(extent, boundary, t_ext=0.4, t_bound=0.2):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "    extent : extent prediction\n",
    "    boundary : boundary prediction\n",
    "    t_ext : threshold for extent\n",
    "    t_bound : threshold for boundary\n",
    "    OUTPUT:\n",
    "    instances\n",
    "    \"\"\"\n",
    "\n",
    "    # Threshold extent mask\n",
    "    ext_binary = np.uint8(extent >= t_ext)\n",
    "\n",
    "    # Artificially create strong boundaries for\n",
    "    # pixels with non-field labels\n",
    "    input_hws = np.copy(boundary)\n",
    "    input_hws[ext_binary == 0] = 1\n",
    "\n",
    "    # Create the directed graph\n",
    "    size = input_hws.shape[:2]\n",
    "    graph = hg.get_8_adjacency_graph(size)\n",
    "    edge_weights = hg.weight_graph(\n",
    "        graph,\n",
    "        input_hws,\n",
    "        hg.WeightFunction.mean\n",
    "    )\n",
    "\n",
    "    tree, altitudes = hg.watershed_hierarchy_by_dynamics(\n",
    "        graph,\n",
    "        edge_weights\n",
    "    )\n",
    "    \n",
    "    # Get individual fields\n",
    "    # by cutting the graph using altitude\n",
    "    instances = hg.labelisation_horizontal_cut_from_threshold(\n",
    "        tree,\n",
    "        altitudes,\n",
    "        threshold=t_bound)\n",
    "    \n",
    "    instances[ext_binary == 0] = -1\n",
    "\n",
    "    return instances\n",
    "\n",
    "def get_IoUs(extent_true, extent_pred, boundary_pred, t_ext=0.4, \n",
    "             t_bound=0.2, plot=False, sample_size=0.05, border_limit=10): # , used_fields_path=None, tile=None\n",
    "    \n",
    "    # initiate dictionary to export used field_numbers\n",
    "    k = ['tile','t_ext','t_bound', 'fieldID'] #'medianIoU', 'meanIoU', 'IoU_50', 'IoU_80']\n",
    "    v = [list() for i in range(len(k))]\n",
    "    res = dict(zip(k, v))\n",
    "\n",
    "    # get predicted instance segmentation\n",
    "    instances_pred = InstSegm(extent_pred, boundary_pred, t_ext=t_ext, t_bound=t_bound)\n",
    "    instances_pred = measure.label(instances_pred, background=-1) # shouldn't that be 0\n",
    "    \n",
    "    # get instances from ground truth label\n",
    "    binary_true = extent_true > 0\n",
    "    instances_true = measure.label(binary_true, background=0, connectivity=1)\n",
    "   \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "        ax[0].imshow(instances_true)\n",
    "        ax[1].imshow(instances_pred)\n",
    "        plt.show()\n",
    "    \n",
    "    # loop through true fields\n",
    "    field_values = np.unique(instances_true)\n",
    "    # here subsetting\n",
    "    field_values = np.random.choice(field_values, size=int(sample_size * len(field_values)), replace=False)\n",
    "\n",
    "    best_IoUs = []\n",
    "    field_IDs = []\n",
    "    field_sizes = []\n",
    "\n",
    "    for field_value in field_values:\n",
    "        if field_value == 0:\n",
    "            continue # move on to next value\n",
    "    \n",
    "        this_field = instances_true == field_value\n",
    "        # check if field is close to border and throw away if too close\n",
    "        if TooCloseToBorder(this_field, border_limit):\n",
    "            continue\n",
    "        # else:\n",
    "            # if used_fields_path != None:\n",
    "            #     res['tile'].append(tile)\n",
    "            #     res['t_ext'].append(t_ext)\n",
    "            #     res['t_bound'].append(t_bound)\n",
    "            #     res['fieldID'].append(field_value)\n",
    "\n",
    "        field_IDs.append(field_value)\n",
    "        field_sizes.append(np.sum(this_field))\n",
    "        \n",
    "        # find predicted fields that intersect with true field\n",
    "        intersecting_fields = this_field * instances_pred\n",
    "        intersect_values = np.unique(intersecting_fields)\n",
    "        intersect_fields = np.isin(instances_pred, intersect_values[1:])\n",
    "        \n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "            ax[0].imshow(this_field)\n",
    "            ax[1].imshow(intersect_fields)\n",
    "            plt.show()\n",
    "        \n",
    "        # compute IoU for each intersecting field\n",
    "        field_IoUs = []\n",
    "        for intersect_value in intersect_values:\n",
    "            if intersect_value == 0:\n",
    "                continue # move on to next value\n",
    "            pred_field = instances_pred == intersect_value\n",
    "            union = this_field + pred_field > 0\n",
    "            intersection = (this_field * pred_field) > 0\n",
    "            IoU = np.sum(intersection) / np.sum(union)\n",
    "            field_IoUs.append(IoU)\n",
    "    \n",
    "        # take maximum IoU - this is the IoU for this true field\n",
    "        if len(field_IoUs) > 0:\n",
    "            best_IoUs.append(np.max(field_IoUs))\n",
    "        else:\n",
    "            best_IoUs.append(0)\n",
    "    \n",
    "    # df  = pd.DataFrame(data = res)\n",
    "    # df.to_csv(f'{used_fields_path}_{tile}_{t_ext}_{t_bound}.csv', index=False)\n",
    "\n",
    "    return best_IoUs, field_IDs, field_sizes\n",
    "\n",
    "\n",
    "def makeTif_np_to_matching_tif(array, tif_path, out_folder, ending):\n",
    "    ds = gdal.Open(tif_path)\n",
    "    gtiff_driver = gdal.GetDriverByName('GTiff')\n",
    "    file_name = tif_path.split('/')[-1].split('.')[0]\n",
    "    out_ds = gtiff_driver.Create(f'{out_folder}/{file_name}{ending}',ds.RasterXSize, ds.RasterYSize, 1, gdal.GDT_Float32)\n",
    "    out_ds.SetGeoTransform(ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(ds.GetProjection())             \n",
    "    out_ds.GetRasterBand(1).WriteArray(array)\n",
    "    del out_ds\n",
    "\n",
    "def TooCloseToBorder(numbered_array, border_limit):\n",
    "    rows, cols = np.where(numbered_array==True)\n",
    "    r,c = numbered_array.shape\n",
    "    if any(value < border_limit for value in [np.min(rows), r - np.max(rows), np.min(cols), c - np.max(cols)]):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on 7. row from 10 rows\n",
      "Starting on 4.column from 10 columns\n",
      "thresholds: 0.1, 0.1\n",
      "thresholds: 0.1, 0.15\n",
      "thresholds: 0.1, 0.2\n",
      "thresholds: 0.1, 0.25\n",
      "thresholds: 0.1, 0.3\n",
      "thresholds: 0.1, 0.35\n",
      "thresholds: 0.1, 0.4\n",
      "thresholds: 0.1, 0.45\n",
      "thresholds: 0.1, 0.5\n",
      "thresholds: 0.15, 0.1\n",
      "thresholds: 0.15, 0.15\n",
      "thresholds: 0.15, 0.2\n",
      "thresholds: 0.15, 0.25\n",
      "thresholds: 0.15, 0.3\n",
      "thresholds: 0.15, 0.35\n",
      "thresholds: 0.15, 0.4\n",
      "thresholds: 0.15, 0.45\n",
      "thresholds: 0.15, 0.5\n",
      "thresholds: 0.2, 0.1\n",
      "thresholds: 0.2, 0.15\n",
      "thresholds: 0.2, 0.2\n",
      "thresholds: 0.2, 0.25\n",
      "thresholds: 0.2, 0.3\n",
      "thresholds: 0.2, 0.35\n",
      "thresholds: 0.2, 0.4\n",
      "thresholds: 0.2, 0.45\n",
      "thresholds: 0.2, 0.5\n",
      "thresholds: 0.25, 0.1\n",
      "thresholds: 0.25, 0.15\n",
      "thresholds: 0.25, 0.2\n",
      "thresholds: 0.25, 0.25\n",
      "thresholds: 0.25, 0.3\n",
      "thresholds: 0.25, 0.35\n",
      "thresholds: 0.25, 0.4\n",
      "thresholds: 0.25, 0.45\n",
      "thresholds: 0.25, 0.5\n",
      "thresholds: 0.3, 0.1\n",
      "thresholds: 0.3, 0.15\n",
      "thresholds: 0.3, 0.2\n",
      "thresholds: 0.3, 0.25\n",
      "thresholds: 0.3, 0.3\n",
      "thresholds: 0.3, 0.35\n",
      "thresholds: 0.3, 0.4\n",
      "thresholds: 0.3, 0.45\n",
      "thresholds: 0.3, 0.5\n",
      "thresholds: 0.35, 0.1\n",
      "thresholds: 0.35, 0.15\n",
      "thresholds: 0.35, 0.2\n",
      "thresholds: 0.35, 0.25\n",
      "thresholds: 0.35, 0.3\n",
      "thresholds: 0.35, 0.35\n",
      "thresholds: 0.35, 0.4\n",
      "thresholds: 0.35, 0.45\n",
      "thresholds: 0.35, 0.5\n",
      "thresholds: 0.4, 0.1\n",
      "thresholds: 0.4, 0.15\n",
      "thresholds: 0.4, 0.2\n",
      "thresholds: 0.4, 0.25\n",
      "thresholds: 0.4, 0.3\n",
      "thresholds: 0.4, 0.35\n",
      "thresholds: 0.4, 0.4\n",
      "thresholds: 0.4, 0.45\n",
      "thresholds: 0.4, 0.5\n",
      "thresholds: 0.45, 0.1\n",
      "thresholds: 0.45, 0.15\n",
      "thresholds: 0.45, 0.2\n",
      "thresholds: 0.45, 0.25\n",
      "thresholds: 0.45, 0.3\n",
      "thresholds: 0.45, 0.35\n",
      "thresholds: 0.45, 0.4\n",
      "thresholds: 0.45, 0.45\n",
      "thresholds: 0.45, 0.5\n",
      "thresholds: 0.5, 0.1\n",
      "thresholds: 0.5, 0.15\n",
      "thresholds: 0.5, 0.2\n",
      "thresholds: 0.5, 0.25\n",
      "thresholds: 0.5, 0.3\n",
      "thresholds: 0.5, 0.35\n",
      "thresholds: 0.5, 0.4\n",
      "thresholds: 0.5, 0.45\n",
      "thresholds: 0.5, 0.5\n"
     ]
    }
   ],
   "source": [
    "# load the predictions and labels\n",
    "\n",
    "predictions =  '/data/fields/output/predictions/FORCE/BRANDENBURG/vrt/256_20_masked_chipsvrt.vrt' # predictions straight from GPU \n",
    "reference =  '/data/fields/IACS/Auxiliary/GSA-DE_BRB-2019_All_agromask_linecrop_prediction_extent.tif' # mask from IACS\n",
    "\n",
    "result_dir = '/data/fields/Auxiliary/grid_search/' + predictions.split('/')[-1].split('.')[0] + '_' + reference.split('/')[-1].split('.')[0]\n",
    "\n",
    "# make a dictionary for export\n",
    "k = ['tile','t_ext','t_bound', 'IoU', 'field_IDs', 'field_sizes'] #'medianIoU', 'meanIoU', 'IoU_50', 'IoU_80']\n",
    "v = [list() for i in range(len(k))]\n",
    "res = dict(zip(k, v))\n",
    "# mIoUs = []\n",
    "# mnIoUs = []\n",
    "# IoU_50s = []\n",
    "# IoU_80s = []\n",
    "\n",
    "\n",
    "# tile predictions in prds --> total extent encompasses 90 Force Tiles (+ a few rows and cols that will be neglected as they are outside of study area)\n",
    "pred_ds = gdal.Open(predictions)\n",
    "rows, cols = pred_ds.RasterYSize, pred_ds.RasterXSize\n",
    "tiles = 10\n",
    "\n",
    "row_start = [i for i in range(0, rows, math.floor(rows/tiles))]\n",
    "row_end = [i for i in range (math.floor(rows/tiles), rows, math.floor(rows/tiles))]\n",
    "row_start = row_start[:len(row_end)] \n",
    "\n",
    "col_start = [i for i in range(0, cols, math.floor(cols/tiles))]\n",
    "col_end = [i for i in range (math.floor(cols/tiles), cols, math.floor(cols/tiles))]\n",
    "col_start = col_start[:len(col_end)] \n",
    "\n",
    "# read in vrt in tiles\n",
    "for i in [6]:# range(len(row_end)):\n",
    "\n",
    "    print(f'Starting on {i+1}. row from {len(row_end)} rows')\n",
    "    \n",
    "    for j in [3]:# range(len(col_end)):\n",
    "        \n",
    "        print(f'Starting on {j+1}.column from {len(col_end)} columns')\n",
    "        # make identifier for tile for csv\n",
    "        tile = f'{str(i)}_{str(j)}'\n",
    "        #s ubset the prediction of fields read-in\n",
    "        extent_pred = pred_ds.GetRasterBand(1).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i]) # goes into InstSegm --> image of crop probability\n",
    "        # check if prediction subset of fields actually contains data\n",
    "        if len(np.unique(extent_pred)) == 1:\n",
    "            continue\n",
    "        # load predicted boundary prob subset\n",
    "        boundary_pred = pred_ds.GetRasterBand(2).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i]) # goes into InstSegm --> image of boundary probability\n",
    "        # load IACS reference\n",
    "        ref_ds = gdal.Open(reference)\n",
    "        extent_true = ref_ds.GetRasterBand(1).ReadAsArray(col_start[j], row_start[i], col_end[j] - col_start[j], row_end[i] - row_start[i]) # goes into InstSegm --> image of crop probability\n",
    "        \n",
    "        # set the parameter combinations and test combinations\n",
    "        t_exts = [i/100 for i in range(10,55,5)] \n",
    "        t_bounds = [i/100 for i in range(10,55,5)]\n",
    "\n",
    "        for t_ext in t_exts:\n",
    "            for t_bound in t_bounds:\n",
    "                print('thresholds: ' + str(t_ext) + ', ' +str(t_bound))\n",
    "                #IoUs = []\n",
    "\n",
    "                # reference = gdal.Open(refs[i]).ReadAsArray()\n",
    "                # extent_true = np.squeeze(reference[0])\n",
    "\n",
    "                # prediction = gdal.Open(prds[i]).ReadAsArray()\n",
    "                # extent_pred = np.squeeze(prediction[0]) # goes into InstSegm --> image of crop probability\n",
    "                # boundary_pred = np.squeeze(prediction[1]) # goes into InstSegm --> image of boundary probability\n",
    "\n",
    "                img_IoUs, field_IDs, field_sizes = get_IoUs(extent_true, extent_pred, boundary_pred, t_ext=t_ext, t_bound=t_bound,\n",
    "                                    sample_size=0.01 ,border_limit=10)\n",
    "                #img_IoUs, _ = get_IoUs_scores(extent_true, extent_pred, boundary_pred, t_ext=t_ext, t_bound=t_bound, t_semc=t_semc)\n",
    "                #IoUs = IoUs + img_IoUs\n",
    "                for e, IoUs in enumerate(img_IoUs):\n",
    "                    res['tile'].append(tile)\n",
    "                    res['t_ext'].append(t_ext)\n",
    "                    res['t_bound'].append(t_bound)\n",
    "                    res['IoU'].append(IoUs)\n",
    "                    res['field_IDs'].append(field_IDs[e])\n",
    "                    res['field_sizes'].append(field_sizes[e])\n",
    "                # res['medianIoU'].append(np.median(IoUs))\n",
    "                # res['meanIoU'].append(np.mean(IoUs))\n",
    "                # res['IoU_50'].append(np.sum(np.array(IoUs) > 0.5) / len(IoUs))\n",
    "                # res['IoU_80'].append(np.sum(np.array(IoUs) > 0.8) / len(IoUs))\n",
    "                # mIoUs.append(np.median(IoUs))\n",
    "                # mnIoUs.append(np.mean(IoUs))\n",
    "                # IoU_50s.append(np.sum(np.array(IoUs) > 0.5) / len(IoUs))\n",
    "                # IoU_80s.append(np.sum(np.array(IoUs) > 0.8) / len(IoUs))\n",
    "\n",
    "# # hp_df = pd.DataFrame({\n",
    "# #     't_ext': np.repeat(t_exts, len(t_bounds)),\n",
    "# #     't_bound': np.tile(t_bounds, len(t_exts)),\n",
    "# #     'medianIoU': mIoUs,\n",
    "# #     'meanIoU': mnIoUs,\n",
    "# #     'IoU_50': IoU_50s,\n",
    "# #     'IoU_80': IoU_80s\n",
    "# # })\n",
    "# # hp_df.to_csv(os.path.join(results_dir, 'IoU_hyperparameter_tuning_full.csv'), index=False)\n",
    "df  = pd.DataFrame(data = res)\n",
    "df.to_csv(result_dir + '_IoU_hyperparameter_tuning_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TooCloseToBorder(numbered_array, border_limit):\n",
    "    rows, cols = np.where(numbered_array==True)\n",
    "    r,c = this_field.shape\n",
    "    if any(value < border_limit for value in [np.min(rows), r - np.max(rows), np.min(cols), c - np.max(cols)]):\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buh\n",
      "gfgdf\n",
      "buh\n",
      "gfgdf\n",
      "buh\n",
      "gfgdf\n",
      "buh\n",
      "gfgdf\n",
      "buh\n",
      "gfgdf\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
