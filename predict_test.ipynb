{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      " @@@@@@@@@@@@@ Going DOWN @@@@@@@@@@@@@@@@@@@ \n",
      "depth:= 0, layer_dim_in: 96, layer_dim: 96, stage_depth::2, spatial_size::(32, 32), scales::[16, 8, 8]\n",
      "depth:= 1, layer_dim_in: 96, layer_dim: 192, stage_depth::2, spatial_size::(16, 16), scales::[32, 4, 4]\n",
      "depth:= 2, layer_dim_in: 192, layer_dim: 384, stage_depth::5, spatial_size::(8, 8), scales::[64, 2, 2]\n",
      "depth:= 3, layer_dim_in: 384, layer_dim: 768, stage_depth::2, spatial_size::(4, 4), scales::[128, 1, 1]\n",
      " XXXXXXXXXXXXXXXXXXXXX Coming up XXXXXXXXXXXXXXXXXXXXXXXXX \n",
      "depth:= 4, layer_dim_in: 384, layer_dim: 384, stage_depth::5, spatial_size::(8, 8), scales::[64, 2, 2]\n",
      "depth:= 5, layer_dim_in: 192, layer_dim: 192, stage_depth::2, spatial_size::(16, 16), scales::[32, 4, 4]\n",
      "depth:= 6, layer_dim_in: 96, layer_dim: 96, stage_depth::2, spatial_size::(32, 32), scales::[16, 8, 8]\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n",
      "torch.Size([1, 4, 6, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import rasterio, glob, xarray as xr\n",
    "import os,sys\n",
    "import albumentations as A\n",
    "from albumentations.core.transforms_interface import  ImageOnlyTransform\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(r'/home/repos')\n",
    "from torch.utils.data import DataLoader                                                                                 \n",
    "from tfcl.models.ptavit3d.ptavit3d_dn import ptavit3d_dn       \n",
    "from tfcl.nn.loss.ftnmt_loss import ftnmt_loss               \n",
    "from tfcl.utils.classification_metric import Classification  \n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def getFilelist(originpath, ftyp):\n",
    "    files = os.listdir(originpath)\n",
    "    out   = []\n",
    "    for i in files:\n",
    "        if i.split('.')[-1] in ftyp:\n",
    "            if originpath.endswith('/'):\n",
    "                out.append(originpath + i)\n",
    "            else:\n",
    "                out.append(originpath + '/' + i)\n",
    "        # else:\n",
    "        #     print(\"non-matching file - {} - found\".format(i.split('.')[-1]))\n",
    "    return out\n",
    "\n",
    "def export_np_to_tif(arr, src, path, name):\n",
    "    with rasterio.open(\n",
    "            path + name + '.tif',\n",
    "            'w',\n",
    "            crs=None,#src.crs,\n",
    "            nodata=None, # change if data has nodata value\n",
    "            transform=src.transform,\n",
    "            driver='GTiff',\n",
    "            height=arr.shape[1],\n",
    "            width=arr.shape[2],\n",
    "            count=arr.shape[0],\n",
    "            dtype=arr.dtype\n",
    "        ) as dst:\n",
    "            for i in range(arr.shape[0]):\n",
    "                dst.write(arr[i], i + 1)\n",
    "# Normalization and transform functions\n",
    "\n",
    "class AI4BNormal_S2(object):\n",
    "    \"\"\"\n",
    "    class for Normalization of images, per channel, in format CHW \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "\n",
    "        self._mean_s2 = np.array([5.4418573e+02, 7.6761194e+02, 7.1712860e+02, 2.8561428e+03 ]).astype(np.float32) \n",
    "        self._std_s2  = np.array( [3.7141626e+02, 3.8981952e+02, 4.7989127e+02 ,9.5173022e+02]).astype(np.float32) \n",
    "\n",
    "    def __call__(self,img):\n",
    "\n",
    "        temp = img.astype(np.float32)\n",
    "        temp2 = temp.T\n",
    "        temp2 -= self._mean_s2\n",
    "        temp2 /= self._std_s2\n",
    "\n",
    "        temp = temp2.T\n",
    "        return temp\n",
    "    \n",
    "class TrainingTransformS2(object):\n",
    "    # Built on Albumentations, this provides geometric transformation only  \n",
    "    def __init__(self,  prob = 1., mode='train', norm = AI4BNormal_S2() ):\n",
    "        self.geom_trans = A.Compose([\n",
    "                    A.RandomCrop(width=128, height=128, p=1.0),  # Always apply random crop\n",
    "                    A.OneOf([\n",
    "                        A.HorizontalFlip(p=1),\n",
    "                        A.VerticalFlip(p=1),\n",
    "                        A.ElasticTransform(p=1), # VERY GOOD - gives perspective projection, really nice and useful - VERY SLOW   \n",
    "                        A.GridDistortion(distort_limit=0.4,p=1.),\n",
    "                        A.ShiftScaleRotate(shift_limit=0.25, scale_limit=(0.75,1.25), rotate_limit=180, p=1.0), # Most important Augmentation   \n",
    "                        ],p=1.)\n",
    "                    ],\n",
    "            additional_targets={'imageS1': 'image','mask':'mask'},\n",
    "            p = prob)\n",
    "        if mode=='train':\n",
    "            self.mytransform = self.transform_train\n",
    "        elif mode =='valid':\n",
    "            self.mytransform = self.transform_valid\n",
    "        else:\n",
    "            raise ValueError('transform mode can only be train or valid')\n",
    "            \n",
    "            \n",
    "        self.norm = norm\n",
    "        \n",
    "    def transform_valid(self, data):\n",
    "        timgS2, tmask = data\n",
    "        if self.norm is not None:\n",
    "            timgS2 = self.norm(timgS2)\n",
    "        \n",
    "        tmask= tmask \n",
    "        return timgS2,  tmask.astype(np.float32)\n",
    "\n",
    "    def transform_train(self, data):\n",
    "        timgS2, tmask = data\n",
    "        \n",
    "        if self.norm is not None:\n",
    "            timgS2 = self.norm(timgS2)\n",
    "\n",
    "        tmask= tmask \n",
    "        tmask = tmask.astype(np.float32)\n",
    "        # Special treatment of time series\n",
    "        c2,t,h,w = timgS2.shape\n",
    "        #print (c2,t,h,w)              \n",
    "        timgS2 = timgS2.reshape(c2*t,h,w)\n",
    "        result = self.geom_trans(image=timgS2.transpose([1,2,0]),\n",
    "                                 mask=tmask.transpose([1,2,0]))\n",
    "        timgS2_t = result['image']\n",
    "        tmask_t  = result['mask']\n",
    "        timgS2_t = timgS2_t.transpose([2,0,1])\n",
    "        tmask_t = tmask_t.transpose([2,0,1])\n",
    "        \n",
    "        c2t,h2,w2 = timgS2_t.shape\n",
    "\n",
    "        \n",
    "        timgS2_t = timgS2_t.reshape(c2,t,h2,w2)\n",
    "        return timgS2_t,  tmask_t\n",
    "    def __call__(self, *data):\n",
    "        return self.mytransform(data)\n",
    "\n",
    "class VALIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data=r'//home/ai4boundaries/sentinel2/'):\n",
    "        \n",
    "        self.flnames_s2_img = sorted(glob.glob(os.path.join(path_to_data,r'images/' + 'LU' + '/*.nc')))\n",
    "        self.flnames_s2_mask = sorted(glob.glob(os.path.join(path_to_data,r'masks/' + 'LU' + '/*.tif')))\n",
    "        \n",
    "        assert len(self.flnames_s2_img) == len(self.flnames_s2_mask), ValueError(\"Some problem, the masks and images are not in the same numbers, aborting\")\n",
    "        \n",
    "        tlen = len(self.flnames_s2_img)\n",
    "        \n",
    "                                                                         \n",
    "    # Helper function to read nc to raster \n",
    "    def ds2rstr(self,tname):\n",
    "        variables2use=['B2','B3','B4','B8'] # ,'NDVI']\n",
    "        ds = xr.open_dataset(tname)\n",
    "        ds_np = np.concatenate([ds[var].values[None] for var in variables2use],0)\n",
    "\n",
    "        return ds_np\n",
    "\n",
    "    def read_mask(self,tname):\n",
    "        return rasterio.open(tname).read((1,2,3))\n",
    "\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        tname_img = self.flnames_s2_img[idx]\n",
    "        tname_mask = self.flnames_s2_mask[idx]\n",
    "        \n",
    "        timg = self.ds2rstr(tname_img)\n",
    "        tmask = self.read_mask(tname_mask)\n",
    "        \n",
    "            \n",
    "        return timg, tmask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.flnames_s2_img)\n",
    "\n",
    "\n",
    "local_rank = 0\n",
    "# torch.cuda.set_device(local_rank)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "country = 'ES_nb_10epochs_7'\n",
    "NClasses = 1\n",
    "nf = 96\n",
    "verbose = True\n",
    "model_config = {'in_channels': 4,\n",
    "                'spatial_size_init': (128, 128),\n",
    "                'depths': [2, 2, 5, 2],\n",
    "                'nfilters_init': nf,\n",
    "                'nheads_start': nf // 4,\n",
    "                'NClasses': NClasses,\n",
    "                'verbose': verbose,\n",
    "                'segm_act': 'sigmoid'}\n",
    "\n",
    "modeli = ptavit3d_dn(**model_config).to(device)\n",
    "modeli.load_state_dict(torch.load('/home/output/models/model_state_' + country + '.pth'))    \n",
    "\n",
    "model = modeli.to(device) # Set model to gpu\n",
    "model.eval()\n",
    "\n",
    "\n",
    "vdata = VALIDataset()\n",
    "\n",
    "preds = []\n",
    "\n",
    "valid_loader = DataLoader(dataset=vdata, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "trg =  sorted(glob.glob(os.path.join('/home/ai4boundaries/sentinel2/masks/' + 'LU' + '/*.tif')))\n",
    "\n",
    "for i, tupi in enumerate(valid_loader):\n",
    "    image, label = tupi\n",
    "    print(image.shape)\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        pred = model(image.cuda())\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "\n",
    "    outDir = '/home/output/predictions/' + country\n",
    "    os.makedirs(outDir, exist_ok=True)\n",
    "    export_np_to_tif(preds[i][0,:,:,:], rasterio.open(trg[i]), outDir, '/' + country + '_pred_LU_' + trg[i].split('/')[-1].split('_')[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(preds))\n",
    "print(len(preds[0]))\n",
    "def export_np_to_tif(arr, src, path, name):\n",
    "    with rasterio.open(\n",
    "            path + name + '.tif',\n",
    "            'w',\n",
    "            crs=None,#src.crs,\n",
    "            nodata=None, # change if data has nodata value\n",
    "            transform=src.transform,\n",
    "            driver='GTiff',\n",
    "            height=arr.shape[1],\n",
    "            width=arr.shape[2],\n",
    "            count=arr.shape[0],\n",
    "            dtype=arr.dtype\n",
    "        ) as dst:\n",
    "            for i in range(arr.shape[0]):\n",
    "                dst.write(arr[i], i + 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
