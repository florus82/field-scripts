{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.2 (you have 1.4.13). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import rasterio, glob, xarray as xr\n",
    "import os,sys\n",
    "import albumentations as A\n",
    "from albumentations.core.transforms_interface import  ImageOnlyTransform\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(r'/home/repos')\n",
    "from torch.utils.data import DataLoader                                                                                 \n",
    "from tfcl.models.ptavit3d.ptavit3d_dn import ptavit3d_dn       \n",
    "from tfcl.nn.loss.ftnmt_loss import ftnmt_loss               \n",
    "from tfcl.utils.classification_metric import Classification  \n",
    "from datetime import datetime   \n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast, GradScaler\n",
    "import pandas as pd\n",
    "import random\n",
    "from rocksdbutils_copy import * \n",
    "\n",
    "# Set this to False for training\n",
    "#DEBUG=True\n",
    "DEBUG=False\n",
    "\n",
    "\n",
    "\n",
    "# Normalization and transform functions\n",
    "\n",
    "class AI4BNormal_S2(object):\n",
    "    \"\"\"\n",
    "    class for Normalization of images, per channel, in format CHW \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "\n",
    "        self._mean_s2 = np.array([5.4418573e+02, 7.6761194e+02, 7.1712860e+02, 2.8561428e+03 ]).astype(np.float32) \n",
    "        self._std_s2  = np.array( [3.7141626e+02, 3.8981952e+02, 4.7989127e+02 ,9.5173022e+02]).astype(np.float32) \n",
    "\n",
    "    def __call__(self,img):\n",
    "\n",
    "        temp = img.astype(np.float32)\n",
    "        temp2 = temp.T\n",
    "        temp2 -= self._mean_s2\n",
    "        temp2 /= self._std_s2\n",
    "\n",
    "        temp = temp2.T\n",
    "        return temp\n",
    "    \n",
    "class TrainingTransformS2(object):\n",
    "    # Built on Albumentations, this provides geometric transformation only  \n",
    "    def __init__(self,  prob = 1., mode='train', norm = AI4BNormal_S2()):\n",
    "        self.geom_trans = A.Compose([\n",
    "                    # A.RandomCrop(width=128, height=128, p=1.0),  # Always apply random crop\n",
    "                    # A.OneOf([\n",
    "                    #     A.HorizontalFlip(p=1),\n",
    "                    #     A.VerticalFlip(p=1),\n",
    "                    #     A.ElasticTransform(p=1), # VERY GOOD - gives perspective projection, really nice and useful - VERY SLOW   \n",
    "                    #     A.GridDistortion(distort_limit=0.4,p=1.),\n",
    "                    #     A.ShiftScaleRotate(shift_limit=0.25, scale_limit=(0.75,1.25), rotate_limit=180, p=1.0), # Most important Augmentation   \n",
    "                    #     ],p=1.)\n",
    "                    A.HorizontalFlip(p=1),\n",
    "                    A.VerticalFlip(p=1),\n",
    "                    A.ElasticTransform(p=1), # VERY GOOD - gives perspective projection, really nice and useful - VERY SLOW   \n",
    "                    A.GridDistortion(distort_limit=0.4,p=1.),\n",
    "                    A.ShiftScaleRotate(shift_limit=0.25, scale_limit=(0.75,1.25), rotate_limit=180, p=1.0), # Most important Augmentation   \n",
    "                    ],\n",
    "            additional_targets={'imageS1': 'image','mask':'mask'},\n",
    "            p = prob)\n",
    "        if mode=='train':\n",
    "            self.mytransform = self.transform_train\n",
    "        elif mode =='valid':\n",
    "            self.mytransform = self.transform_valid\n",
    "        else:\n",
    "            raise ValueError('transform mode can only be train or valid')\n",
    "            \n",
    "            \n",
    "        self.norm = norm\n",
    "        \n",
    "    def transform_valid(self, data):\n",
    "        timgS2, tmask = data\n",
    "        if self.norm is not None:\n",
    "            timgS2 = self.norm(timgS2)\n",
    "        \n",
    "        tmask= tmask \n",
    "        return timgS2,  tmask.astype(np.float32)\n",
    "\n",
    "    def transform_train(self, data):\n",
    "        timgS2, tmask = data\n",
    "        \n",
    "        if self.norm is not None:\n",
    "            timgS2 = self.norm(timgS2)\n",
    "\n",
    "        tmask= tmask \n",
    "        tmask = tmask.astype(np.float32)\n",
    "        # Special treatment of time series\n",
    "        c2,t,h,w = timgS2.shape\n",
    "        #print (c2,t,h,w)              \n",
    "        timgS2 = timgS2.reshape(c2*t,h,w)\n",
    "        result = self.geom_trans(image=timgS2.transpose([1,2,0]),\n",
    "                                 mask=tmask.transpose([1,2,0]))\n",
    "        timgS2_t = result['image']\n",
    "        tmask_t  = result['mask']\n",
    "        timgS2_t = timgS2_t.transpose([2,0,1])\n",
    "        tmask_t = tmask_t.transpose([2,0,1])\n",
    "        \n",
    "        c2t,h2,w2 = timgS2_t.shape\n",
    "\n",
    "        \n",
    "        timgS2_t = timgS2_t.reshape(c2,t,h2,w2)\n",
    "        return timgS2_t,  tmask_t\n",
    "    def __call__(self, *data):\n",
    "        return self.mytransform(data)\n",
    "\n",
    "\n",
    "def mtsk_loss(preds, labels,criterion, NClasses=1):                   \n",
    "    # Multitasking loss,    segmentation / boundaries/ distance     \n",
    "                                                                    \n",
    "    pred_segm  = preds[:,:NClasses]                                 \n",
    "    pred_bound = preds[:,NClasses:2*NClasses]                       \n",
    "    pred_dists = preds[:,2*NClasses:3*NClasses]                     \n",
    "                                                                    \n",
    "                                                                    \n",
    "                                                                    \n",
    "    # Multitasking loss                                             \n",
    "    label_segm  = labels[:,:NClasses]                               \n",
    "    label_bound = labels[:,NClasses:2*NClasses]                     \n",
    "    label_dists = labels[:,2*NClasses:3*NClasses]                   \n",
    "                                                                    \n",
    "                    \n",
    "    #print(preds.shape, labels.shape)\n",
    "\n",
    "    loss_segm  = criterion(pred_segm,   label_segm)                 \n",
    "    loss_bound = criterion(pred_bound, label_bound)                 \n",
    "    loss_dists = criterion(pred_dists, label_dists)                 \n",
    "                                                                                                                                        \n",
    "    return (loss_segm+loss_bound+loss_dists)/3.0     \n",
    "\n",
    "\n",
    "# create output dictionary\n",
    "keys = ['Epoch', 'Iteration','Loss', 'Mode']\n",
    "vals = [list() for _ in range(len(keys))]\n",
    "res  = dict(zip(keys, vals))\n",
    "\n",
    "keys = ['Epoch', 'MCC']\n",
    "vals = [list() for _ in range(len(keys))]\n",
    "res2  = dict(zip(keys, vals))\n",
    "\n",
    "rnd = random.randint(1,1000)\n",
    "\n",
    "def monitor_epoch(model, epoch, datagen_valid, NClasses=1):\n",
    "    metric_target = Classification(num_classes=NClasses, task='binary').to(0)\n",
    "    model.eval()\n",
    "\n",
    "    valid_pbar = tqdm(datagen_valid, desc=f\"Validating Epoch {epoch}\", position=1, leave=False)\n",
    "    for idx, data in enumerate(valid_pbar):\n",
    "        images, labels = data\n",
    "        images = images.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            preds_target = model(images)\n",
    "\n",
    "        criterionV = ftnmt_loss()\n",
    "        lossi = mtsk_loss(preds_target, labels, criterionV, NClasses)\n",
    "\n",
    "        res['Epoch'].append(epoch)\n",
    "        res['Iteration'].append(idx)\n",
    "        res['Loss'].append(lossi.item())\n",
    "        res['Mode'].append('Valid')\n",
    "\n",
    "\n",
    "        pred_segm = preds_target[:, :NClasses]\n",
    "        label_segm = labels[:, :NClasses]\n",
    "\n",
    "        metric_target(pred_segm, label_segm)\n",
    "     \n",
    "        if DEBUG and idx > 5:\n",
    "            break\n",
    "    \n",
    "    metric_kwargs_target = metric_target.compute()\n",
    "    \n",
    "\n",
    "    kwargs = {'epoch': epoch}\n",
    "    for k, v in metric_kwargs_target.items():\n",
    "        kwargs[k] = v.cpu().numpy()\n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    # dummy variable to keep track of mcc\n",
    "    conti = [1,2]\n",
    "    mcc_dum = 0\n",
    "    num_epochs = args.epochs\n",
    "    batch_size = args.batch_size\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "    local_rank = 0\n",
    "    # torch.cuda.set_device(local_rank)\n",
    "    torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    NClasses = 1\n",
    "    nf = 96\n",
    "    verbose = True\n",
    "    model_config = {'in_channels': 4,\n",
    "                    'spatial_size_init': (128, 128),\n",
    "                    'depths': [2, 2, 5, 2],\n",
    "                    'nfilters_init': nf,\n",
    "                    'nheads_start': nf // 4,\n",
    "                    'NClasses': NClasses,\n",
    "                    'verbose': verbose,\n",
    "                    'segm_act': 'sigmoid'}\n",
    "\n",
    "    model = ptavit3d_dn(**model_config).to(local_rank)\n",
    "    criterion = ftnmt_loss()\n",
    "    criterion_features = ftnmt_loss(axis=[-3, -2, -1])\n",
    "    optimizer = torch.optim.RAdam(model.parameters(), lr=1e-3, eps=1.e-6)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    train_dataset = RocksDBDataset('/home/output/rocks_db/ES_no_empty_label.db/train.db')\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                              shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    valid_dataset = RocksDBDataset('/home/output/rocks_db/ES_no_empty_label.db/valid.db')\n",
    "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size,\n",
    "                              shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    start = datetime.now()\n",
    "    epoch_pbar = tqdm(range(num_epochs), desc=\"Epochs\", position=0)\n",
    "    for epoch in epoch_pbar:\n",
    "        tot_loss = 0\n",
    "        model.train() # train function from ptavit3d_dn(torch.nn.Module) is called\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Training Epoch {epoch}\", position=1, leave=False)\n",
    "        for i, data in enumerate(train_pbar):\n",
    "            if DEBUG and i > 5:\n",
    "                break\n",
    "\n",
    "            images, labels = data\n",
    "            images = images.to(local_rank, non_blocking=True)\n",
    "            labels = labels.to(local_rank, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                preds_target = model(images)\n",
    "                loss = mtsk_loss(preds_target, labels, criterion, NClasses)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            tot_loss += loss.item()\n",
    "            train_pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "               # for export\n",
    "            res['Epoch'].append(epoch)\n",
    "            res['Iteration'].append(i)\n",
    "            res['Loss'].append(loss.item())\n",
    "            res['Mode'].append('Train')\n",
    "\n",
    "        kwargs = monitor_epoch(model, epoch, valid_loader, NClasses)\n",
    "        kwargs['tot_train_loss'] = tot_loss\n",
    "        # for export\n",
    "        res2['Epoch'].append(epoch)\n",
    "        res2['MCC'].append(kwargs['mcc'])\n",
    "\n",
    "        # check if mcc higher than ever observed\n",
    "        if kwargs['mcc'] > mcc_dum:\n",
    "            mcc_dum = kwargs['mcc']\n",
    "            conti[0] = model.state_dict()\n",
    "            conti[1] = epoch\n",
    "        \n",
    "     \n",
    "        #res.append \n",
    "        if verbose:\n",
    "            output_str = ', '.join(f'{k}:: {v}, |===|, ' for k, v in kwargs.items())\n",
    "            epoch_pbar.write(output_str)\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Training completed in: \" + str(datetime.now() - start))\n",
    "\n",
    "    country = 'test_no_writable'\n",
    "    torch.save(conti[0], '/home/output/models/model_state_' + country + '_' + str(conti[1]) + '.pth') # \n",
    "\n",
    "    df  = pd.DataFrame(data = res)\n",
    "    df.to_csv('/home/output/loss/loss_' + country + '_' + str(rnd) + '.csv', sep=',',index=False)\n",
    "\n",
    "    df  = pd.DataFrame(data = res2)\n",
    "    df.to_csv('/home/output/loss/MCC_' + country + '_' + str(rnd) + '.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    class Args:\n",
    "        def __init__(self):\n",
    "            self.epochs = 5\n",
    "            self.batch_size = 3 # H100 test - 94GB GPU memory\n",
    "\n",
    "    args = Args()\n",
    "        \n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " @@@@@@@@@@@@@ Going DOWN @@@@@@@@@@@@@@@@@@@ \n",
      "depth:= 0, layer_dim_in: 96, layer_dim: 96, stage_depth::2, spatial_size::(32, 32), scales::[16, 8, 8]\n",
      "depth:= 1, layer_dim_in: 96, layer_dim: 192, stage_depth::2, spatial_size::(16, 16), scales::[32, 4, 4]\n",
      "depth:= 2, layer_dim_in: 192, layer_dim: 384, stage_depth::5, spatial_size::(8, 8), scales::[64, 2, 2]\n",
      "depth:= 3, layer_dim_in: 384, layer_dim: 768, stage_depth::2, spatial_size::(4, 4), scales::[128, 1, 1]\n",
      " XXXXXXXXXXXXXXXXXXXXX Coming up XXXXXXXXXXXXXXXXXXXXXXXXX \n",
      "depth:= 4, layer_dim_in: 384, layer_dim: 384, stage_depth::5, spatial_size::(8, 8), scales::[64, 2, 2]\n",
      "depth:= 5, layer_dim_in: 192, layer_dim: 192, stage_depth::2, spatial_size::(16, 16), scales::[32, 4, 4]\n",
      "depth:= 6, layer_dim_in: 96, layer_dim: 96, stage_depth::2, spatial_size::(32, 32), scales::[16, 8, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py:222: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py:222: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py:222: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py:222: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;66;03m# H100 test - 94GB GPU memory\u001b[39;00m\n\u001b[1;32m      7\u001b[0m args \u001b[38;5;241m=\u001b[39m Args()\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 237\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    238\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(local_rank, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    239\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(local_rank, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "main()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
